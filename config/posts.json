{
  "posts": [
    {
      "content": "\r\nCSS 作为构建前端页面的三驾马车,随着现代前端技术的飞速发展,已经称为描述页面样式不可或缺的部分. 本文将从前端面试题目出发,总结CSS必须掌握的知识点.\r\n<!-- more -->\r\n\r\n\r\n# Questions\r\n\r\n### 1. css sprite是什么?有什么优缺点?\r\n\r\n- 知识点:css sprite\r\n- 重要程度:★★★\r\n- 概念与背景: css sprite是一种用于解决页面图片过多导致大量http请求的解决方案. css sprite将多个小图片拼接到一个图片中，通过background-positon 和元素尺寸调节需要显示的背景图案.\r\n- 优点:\r\n    - 减少HTTP请求数,极大的提高页面加载速度\r\n    - 增加图片信息重复度,提高压缩比,减少图片大小\r\n    - 更换风格方便.只需要在少量图片上修改颜色或者样式即可\r\n- 缺点:\r\n    - 图片合并麻烦\r\n    - 维护不便,修改一个图片可能需要重新布局整个图片样式\r\n\r\n- 实现 (转自MDN教程):\r\n  如果为类名为toolbtn的元素附加一张图片\r\n ```css\r\n.toolbtn{\r\n    background:url(myfile.png);\r\n    display : inline-block;\r\n    height : 20px;\r\n    width : 20px;\r\n}\r\n ```\r\n为设置 background-position 以使每个按钮得到合并后图片中的正确部分，可以在 background 属性中的 url() 后添加 x, y 两个坐标值，或直接使用 background-position 属性。例如：\r\n\r\n ```css\r\n#btn1 {background-position: -20px 0px}\r\n#btn2 {background-position: -40px 0px}\r\n ```\r\n\r\n 这会将 ID 为 btn1 的元素的背景向左移 20px，ID 为 btn2 的元素的背景向左移40px（假设这两个元素都带有 toolbtn 这个类且应用了上面 background 属性中定义的图片背景）\r\n\r\n类似的，你也可以使用下面的代码添加悬停效果：\r\n```css\r\n#btn:hover {\r\n  background-position: <pixels shifted right>px <pixels shifted down>px;\r\n}\r\n```\r\n\r\n\r\n### 2. display:none 与 visibility:hidden 的区别\r\n\r\n- 知识点: display与visibility\r\n- 重要程度:★★\r\n- 概念与背景: 本题考察display与visibility的渲染机制\r\n- display:none; :\r\n    - 会让元素完全从渲染树中消失,渲染时不占任何空间\r\n    - 非继承属性: 子孙节点同样消失,无法通过修改子孙节点属性使子孙节点显示\r\n- visibility:hidden; :\r\n    - 不会让元素从渲染树中消失,渲染时仍然占据控件,只是内容不可见\r\n    - 子孙节点可以通过重新设置 visibility:visible; 使自身显示\r\n    - 修改display属性会导致文档重拍,visibility只会导致内容重新渲染\r\n\r\n\r\n\r\n### 3. link与@import的区别\r\n\r\n- 知识点: 样式文件的引用方式\\FOUC\r\n- 重要程度:★★\r\n- 概念与背景: link与@import都是前端用于引入css文件的方式.但因其作用方式不同,在传统的前端项目中容易遇到一些样式覆盖,FOUC的bug\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "data": {
        "title": "【前端拾遗】CSS知识点",
        "date": "2020-05-21 10:55:48",
        "tags": [
          "前端拾遗"
        ],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "\r\nCSS 作为构建前端页面的三驾马车,随着现代前端技术的飞速发展,已经称为描述页面样式不可或缺的部分. 本文将从前端面试题目出发,总结CSS必须掌握的知识点.\r",
      "fileName": "CSS-Point"
    },
    {
      "content": "\n\n\n> 2014 - 2020 ，两千多个披星戴月，收获良多。对个人负责、参与过的项目进行总结如下。\n\n\n## 项目一： 设备智能管理系统（桌面应用程序）\n\n- 项目描述：一套以发挥数据潜能为核心的智能制造解决方案。主要用于解决当前工厂生产运营中存在的人力、效率、方法、数据价值相关问题，最终帮助工厂向工业4.0转型。\n\n- 个人工作职责：项目负责人，负责项目需求制定、程序开发、资源协调与业务推进。\n\n- 实现技术：BS/CS混合架构 + .NET Winform + MS SQL Server + LinQ + SpringBoot(部分ServerAPI)；\n\n\n  \n![](https://www.xr1228.com//post-images/1589153255940.png)\n\n- 主要模块：设备监控、工艺监控、不良调查\n>   ![](https://www.xr1228.com//post-images/1589153107363.png)\n\n>   ![](https://www.xr1228.com//post-images/1589153172425.png)\n\n>   ![](https://www.xr1228.com//post-images/1589153182823.png)\n\n- 项目难点：\n\n    1. UI 样式 ：Winform作为一款20年前推出的框架，组件UI样式已经显得十分“呆板落伍”。\n    - 解决方案：通过对 MetroFramework 框架的定制开发，实现了样式设计的现代化同时兼具Winform拖动组件设计的便捷性。\n![](https://www.xr1228.com//post-images/1589154078440.png)\n\n    2. 代码执行效率：工业级应用在数据分析过程中要快速处理大量数据（M级），BS架构会极大增加服务器压力，CS架构下用户对于程序卡顿感知较强。\n\n    - 解决方案：数据处理在客户端执行，保证了代码执行效率减少服务器开销。大量使用了多线程方案优化用户体验。\n\n\n## 项目二： 数据透明化平台（Web）\n\n- 项目描述：一套用于工厂数据可视化、展示固定报表，数据监控的Web应用。解决用户复杂的数据处理加工需求，减少重复低效的数据二次处理劳动。固化日报月报，帮助技术部获取实时数据。\n\n- 个人工作职责：全栈开发，主要进行项目的需求检讨与开发。\n\n- 实现技术：AngularJS + SpringBoot + Oracle + Primeng + echarts + d3js\n\n![](https://www.xr1228.com//post-images/1589154673790.png)\n\n## 项目三：基于大数据技术的不良分析平台\n\n- 项目描述：一个基于大数据技术的不良分析平台，将工业生产数据与检测数据进行全面联动，采用特定算法计算影响不良的相关因子，明确不良发生原因。为工厂提供不良监控、自主分析等功能。\n\n- 个人工作职责：项目支援，主要进行项目的前端开发、性能调优。\n\n- 实现技术：AngularJS + SpringBoot + 。。。（保密协议相关）\n\n\n## 项目四：小程序（篇幅有限，将几款小程序合并一起说明）\n\n- 智造之窗：一款用于企业智能制造项目改进、移动端数据展示、新闻、数据交互的微信小程序。\n- i创+提案平台：一款用于企业改善提案上报、审批、数据展示的微信小程序。\n- 全员学习系统：用于单位全员学习、考试、学习情况评比、学习心得展示的钉钉小程序。\n- 资产名片：用于企业固定资产管理、二维码标签自动生成、资产审批的微信小程序。\n- 绩效时钟：用于单位全员绩效管理、任务分解、任务下发的微信小程序。\n\n- 实现技术：小程序原生框架 + Koa2（Nodejs） + MySQL\n\n![](https://www.xr1228.com//post-images/1589385069512.png)\n\n- 项目难点：\n  1. 服务中台：小程序项目具有轻量化、数量多、基本数据(用户信息）一致的特点，为了保障应用的快速开发上线，减少重复代码。将人员信息、项目配置信息、页面配置等进行了服务端中台化。\n  2. UI组件：为保障项目统一性与页面美观，基于ColorUI开发了XRUI框架。通过template与css方式在保障项目美观的同时兼顾了框架的易用性与可拓展性。\n   1. 移动端数据展示：小程序端因为其特定的框架结构，Echarts等可视化工具无法直接使用。采用Canvans方式对echarts进行了定制化（基于echarts for wx）保障了移动端数据可视化功能的执行效率。\n\n![](https://www.xr1228.com//post-images/1589157404629.png)\n\n## 项目五：房车情报（已下线）\n\n- 项目描述：一个为房车情报官方设计的房车展示、新闻展示、车型数据库网站。\n\n- 个人工作职责：项目负责人，负责项目需求制定、程序开发。\n\n- 实现技术：bootStrap + vue + koa2（nodejs） + mySql + sequelize\n\n- 项目难点：\n  1. 静态资源优化：新闻类咨询类网站存在大量静态资源且通常图片尺寸较大。采用Gzip压缩、上传压缩、CDN等方式实现了静态资源的尺寸、访问速度优化。\n  2. 首屏加载与SEO优化：单页应用存在首屏加载与SEO问题，通过首页服务度渲染、组件懒加载、Gzip、h5语义化标签等方式对其进行了优化。\n\n![](https://www.xr1228.com//post-images/1589157977232.jpeg)\n\n\n-------\n\n\n\n###  附：个人简历\n\n![](https://www.xr1228.com//post-images/1589125473530.jpg)\n\n![](https://www.xr1228.com//post-images/1589125514909.jpg)\n",
      "data": {
        "title": "个人项目经历总结",
        "date": "2020-05-10 23:33:14",
        "tags": [
          "值得一读"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/xiangmu.png",
        "isTop": true
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "xiangmu"
    },
    {
      "content": "\n\n## 1. 实现盒子水平垂直居中的几种方案？\n解答：\n\n实现盒子水平垂直居中在flex提出之前，最常用的方法是通过position定位实现，主要有三种方式：\n\n- 方式一: 通过相对父级容器进行定位，缺点:必须知道box的宽高\n```css\nbody{\n    height:100%\n    overflow:hidden;\n    position:relative;  \n}\n.box{\n    width:100px;\n    height:50px;\n    position:absolution;\n    margin-top:-25px;    /* 移动半个box */\n    margin-left:-50px;\n}\n```\n\n- 方式二：缺点：可以不知道box的宽高，但box必须定义宽高\n\n```css\nbody{\n    height:100%\n    overflow:hidden;\n    position:relative;  \n}\n.box{\n    width:100px;\n    height:50px;\n    position:absolution;\n    top:0;    \n    left:0;  \n    right:0;\n    bottom:0;\n    margin:auto 0;  \n}\n```\n\n- 方式三  无需考虑box的宽度与高度，缺点：低版本浏览器兼容性不太好\n\n```css\nbody{\n    height:100%\n    overflow:hidden;\n    position:relative;  \n}\n.box{\n    position:absolution;\n    top:50%;    \n    left:50%;  \n    transform:translate(-50%,-50%);   /* css3中移动位置  */\n}\n```\n\n采用弹性盒子模型后可以使用如下方式：\n\n```css\nbody{\n    height:100%;\n    display:flex;\n    justify-content : center;  //水平居中\n    align-items : center;   //垂直居中\n}\n```\n\n\n还能采用JS来实现盒子模型\n\n```html\n<body>\n    <div class=\"box\">\n    </div>\n    <script>\n        let HTML = document.documentElement,\n            winW = HTML.clientWidth,\n            winH = HTML.clientHeight,\n            boxW = box.offsetWidth\n            boxH = box.offsetHeight;\n        box.style.postion = \"absolution\";\n        box.style.left = winW-boxW)/2 + 'px';\n        box..style.top = ()\n    </script>\n</body>\n```\n``` css\nbody{\n    position:relative;\n}\n\n```\n\n## 2. 盒子模型相关\n\n- 盒子模型分为 ：\n    - 标准盒子模型    box-sizing:content-box\n    - 怪异盒子模型（也就是IE盒子模型）   box-sizing:border-box \n    - 弹性伸缩布局盒子模型（flex）\n\n>标准盒子模型width与height指定的是content的宽高。标准盒子模型有一个明显的缺陷，当我们修改border或padding后盒子整体实际宽高会发生变化，这就会整体页面布局出错。而怪异盒子模型的width与height是盒子整体的宽高，修改其padding与border盒子会自动伸缩content。目前主流的bootstrap等ui组建大部分默认采用了怪异盒子模型。\n\n![](https://www.xr1228.com//post-images/1589074776615.png)\n\n\n![](https://www.xr1228.com//post-images/1589074963770.png)\n\nFLEX盒模型 ：为布局实现提供了灵活性\n\n![](https://www.xr1228.com//post-images/1589075004652.png)\n\n\n## 3.经典布局方案\n\n圣杯布局 ： 左右固定,中间自适应 (双飞翼布局与之类似，不做详细讨论了).圣杯布局和双飞翼布局是前端工程师需要日常掌握的重要布局方式。两者的功能相同，都是为了实现一个两侧宽度固定，中间宽度自适应的三栏布局。\n\n![](https://www.xr1228.com//post-images/1589077300019.png)\n\n实现圣杯布局的要求\n- header和footer各自占领屏幕所有宽度，高度固定。\n- 中间的container是一个三栏布局。\n- 三栏布局两侧宽度固定不变，中间部分自动填充整个区域。\n- 中间部分的高度是三栏中最高的区域的高度。\n\n\n圣杯布局的三种实现方式\n\n1. 浮动\n\n- 先定义好header和footer的样式，使之横向撑满。\n- 在container中的三列设为浮动和相对定位(后面会用到)，center要放在最前面，footer清除浮动。\n- 三列的左右两列分别定宽200px和150px，中间部分center设置100%撑满\n- 这样因为浮动的关系，center会占据整个container，左右两块区域被挤下去了\n- 接下来设置left的 margin-left: -100%;，让left回到上一行最左侧\n- 但这会把center给遮住了，所以这时给外层的container设置 padding-left: 200px;\n- padding-right: 150px;，给left和right空出位置\n- 这时left并没有在最左侧，因为之前已经设置过相对定位，所以通过 left: -200px; 把left拉回最左侧\n- 同样的，对于right区域，设置 margin-right: -150px; 把right拉回第一行\n- 这时右侧空出了150px的空间，所以最后设置 right: -150px;把right区域拉到最右侧就行了\n\n```html\n<html>\n\n<style>\n  body {\n    min-width: 550px;  /* 2x leftContent width + rightContent width */\n    font-weight: bold;\n    font-size: 20px;\n  }\n \n  #header, #footer {\n    background: rgba(29, 27, 27, 0.726);\n    text-align: center;\n    height: 60px;\n    line-height: 60px;\n  }\n  #footer {\n    clear: both;\n  }\n \n  #container {\n    padding-left: 200px;   /* leftContent width */\n    padding-right: 150px;  /* rightContent width */\n    overflow: hidden;\n  }\n \n  #container .column {\n    position: relative;\n    float: left;\n    text-align: center;\n    height: 300px;\n    line-height: 300px;\n  }\n \n  #center {\n    width: 100%;\n    background: rgb(206, 201, 201);\n  }\n \n  #left {\n    width: 200px;           /* leftContent width */\n    right: 200px;           /* leftContent width */\n    margin-left: -100%;\n    background: rgba(95, 179, 235, 0.972);\n  }\n \n  #right {\n    width: 150px;           /* rightContent width */\n    margin-right: -150px;   /* rightContent width */\n    background: rgb(231, 105, 2);\n  }\n \n</style>\n \n<body>\n  <div id=\"header\">#header</div>\n  <div id=\"container\">\n    <div id=\"center\" class=\"column\">#center</div>\n    <div id=\"left\" class=\"column\">#left</div>\n    <div id=\"right\" class=\"column\">#right</div>\n  </div>\n  <div id=\"footer\">#footer</div>\n \n \n</body>\n \n</html>\n\n```\n\n\n2. Flex弹性盒子\n\n- header和footer设置样式，横向撑满。\n- container中的left、center、right依次排布即可\n- 给container设置弹性布局 display: flex;\n- left和right区域定宽，center设置 flex: 1; 即可\n\n```html\n\n<!DOCTYPE html>\n<html>\n<style>\n  body {\n    min-width: 550px;  \n    font-weight: bold;\n    font-size: 20px;\n  }\n  #header, #footer {\n    background: rgba(29, 27, 27, 0.726);\n    text-align: center;\n    height: 60px;\n    line-height: 60px;\n  }\n  #container {\n   display: flex;\n  }\n  #container .column {\n    text-align: center;\n    height: 300px;\n    line-height: 300px;\n  }\n  #center {\n    flex: 1;  /*  自动占用剩余所有空间 */\n    background: rgb(206, 201, 201);\n  }\n  #left {\n    width: 200px;        \n    background: rgba(95, 179, 235, 0.972);\n  }\n  #right {\n    width: 150px;           \n    background: rgb(231, 105, 2);\n  }\n</style>\n \n<body>\n  <div id=\"header\">#header</div>\n  <div id=\"container\">\n    <div id=\"left\" class=\"column\">#left</div>\n    <div id=\"center\" class=\"column\">#center</div>\n    <div id=\"right\" class=\"column\">#right</div>\n  </div>\n  <div id=\"footer\">#footer</div>\n</body>\n \n</html>\n``````\n\n\n3.Grid布局\n\n![](https://www.xr1228.com//post-images/1589078133539.png)\n\n如上图所示，我们把body划分成三行四列的网格，其中有5条列网格线\n\n- 给body元素添加display: grid;属性变成一个grid(网格)\n- 给header元素设置grid-row: 1; 和 grid-column: 1/5; 意思是占据第一行网格的从第一条列网格线开始到第五条列网格线结束\n- 给footer元素设置grid-row: 1; 和 grid-column: 1/5; 意思是占据第三行网格的从第一条列网格线开始到第五条列网格线结束\n- 给left元素设置grid-row: 2; 和 grid-column: 1/2; 意思是占据第二行网格的从第一条列网格线开始到第二条列网格线结束\n- 给center元素设置grid-row: 2; 和 grid-column: 2/4; 意思是占据第二行网格的从第二条列网格线开始到第四条列网格线结束\n- 给right元素设置grid-row: 2; 和 grid-column: 4/5; 意思是占据第二行网格的从第四条列网格线开始到第五条列网格线结束\n\n``` html\n<!DOCTYPE html>\n<html>\n \n<head>\n  <meta charset=\"utf-8\">\n  <script src=\"http://lib.sinaapp.com/js/jquery/2.0.2/jquery-2.0.2.min.js\"></script>\n</head>\n<style>\n  body {\n    min-width: 550px;\n    font-weight: bold;\n    font-size: 20px;\n    display: grid;\n  }\n  #header,\n  #footer {\n    background: rgba(29, 27, 27, 0.726);\n    text-align: center;\n    height: 60px;\n    line-height: 60px;\n  }\n  #header {\n    grid-row: 1;\n    grid-column: 1/5;\n  }\n  #footer {\n    grid-row: 3;\n    grid-column: 1/5;\n  }\n  .column {\n    text-align: center;\n    height: 300px;\n    line-height: 300px;\n  }\n  #left {\n    grid-row: 2;\n    grid-column: 1/2;\n    background: rgba(95, 179, 235, 0.972);\n  }\n  #center {\n    grid-row: 2;\n    grid-column: 2/4;\n    background: rgb(206, 201, 201);\n  }\n  #right {\n    grid-row: 2;\n    grid-column: 4/5;\n    background: rgb(231, 105, 2);\n  }\n</style>\n \n<body>\n  <div id=\"header\">#header</div>\n  <div id=\"left\" class=\"column\">#left</div>\n  <div id=\"center\" class=\"column\">#center</div>\n  <div id=\"right\" class=\"column\">#right</div>\n  <div id=\"footer\">#footer</div>\n</body>\n \n</html>\n```\n\n## 4.移动端的自适应解决方案\n\n- .media\n- rem\n- flex\n- vh/vw\n- .......\n",
      "data": {
        "title": "【前端拾遗】前端布局方案",
        "date": "2020-05-09 01:02:17",
        "tags": [],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/qian-duan-mian-shi-bi-kao-ti.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "qian-duan-mian-shi-bi-kao-ti"
    },
    {
      "content": "\r\n## 一、Cloudera Manager平台的安装\r\n\r\n1. 分析用户的需求\r\n\r\n",
      "data": {
        "title": "【工业与大数据】基于Cloudera Manager进行CDH集群管理运维",
        "date": "2020-03-18 13:57:05",
        "tags": [],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "gong-ye-yu-da-shu-ju-ji-yu-cloudera-manager-jin-xing-cdh-ji-qun-guan-li-yun-wei"
    },
    {
      "content": "\n# 一、流计算的必要性\n\n- 流计算的需求\n    - Map-Reduce，Spark，GraphLab都是批处理模型，会面临如下挑战\n        - Volume 数据量太大以至于存不下全部数据（譬如筛选近十年所有的互联网的词）\n        - Velocity 数据的到来太快以至于用批处理方式来不及处理\n        - 使用批处理框架达到所需要性能的成本太高\n\n\n# 二、什么情况下使用流计算\n  \n    F(X+△X) = F(X)op(△X)\n  \n  计算F(X+△X)时不需要对全部数据集 X+△X进行计算，只需要将X之前的某种处理结果保留下来，并和增量△X处理结果再进行处理。这种处理方式可以看做数据不断增量的方式流入系统并处理，改变系统状态并输出结果。我们把这种方式叫做流计算。\n\n  - 举例：Twitter 大规模实时应用\n    - 平均每秒 6000个tweets，每天约5亿\n    - 对这些tweets及相关的点击进行统计\n\n![](https://www.xr1228.com//post-images/1582112459447.PNG)\n\n# 三、流计算的技术挑战\n\n- 流计算的目标\n    - 实时性/可扩展性：\n        - 批处理任务一般对固定规模数据进行处理，执行时间可以长达几十小时（离线）\n        - 流处理\n            - 数据到达速率变化很大（做负载均衡）\n            - 要么能够处理所有的数据\n            - 要么预先定义好降级处理的方法\n    - 容错：系统的错误与系统的故障\n        - 批处理任务\n            - 数据错误通常由数据清洗阶段完成 \n            - 系统故障有重算或检查点设置等机制 （MapReduce：从中间结果开始重新计算）\n        - 流计算\n            - 数据错误必须实施处理\n            - 系统故障时的容错机制必须是低开销的，而且还能满足实时性\n    - 可编程性\n        - 描述自然\n        - 表达力强\n        - 无需关注（或少关注）容错机制和负载平衡\n\n# 四、流计算的一种简单实现  Worker + Queue （处理+缓冲/路由）\n\n- Worker ： 处理单元\n- Queue ： 缓冲 + 路由 → 解决传入分析系统的数据量不均衡的问题\n\n![](https://www.xr1228.com//post-images/1582162418584.PNG)\n\n数据传入后，通过负载均衡随机进入（或遵循一定规则）被分配到不同的Queue（队列）\nQueue中数据全连接到后续的worker，Worker对数据进行处理，制定接下里要进入的Queue\n处理后的Queue与后续的Worker一一对应，解决并发，数据一致性的问题。\n\nWorker  Queue存在不易扩展，难容错，编码复杂的问题，所以Twitter替换了这种方式，采用了Strom\n\n\n# 五、S4 （Simple Scalable Streaming System）\n-   简单的流处理编程接口\n    -   和MapReduce类似，都是处理key-value\n- 有限容错\n    - 系统节点出错后会重新在备用节点上启动进程\n    - 当前进程状态丢失，但支持非协调式检查点\n    - 在运行期间不能增加或删除系统节点\n\n### 5.1 S4的处理模型 —— Actor模型\n\n- PE（Processiong Element）\n- PE之间通过event进行通信\n- PE的状态互不可见\n- S4框架负责产生PE和消息路由\n\n![](https://www.xr1228.com//post-images/1582162821926.PNG)\n\n### 5.2 S4的设计\n\n- 基于（Key，Attribute）流\n- 输入是（K,A）流，S4进行计算，产生中间结果，并（可能）输出一个流\n\n距离：进行wordCount\n![](https://www.xr1228.com//post-images/1582162914721.PNG)\n\nPE\n-   功能 ：由PE的代码和配置文件定义\n-   处理的事件类型\n-   每个Key的值对应一个PE\n    -   在wordcount中，如果遇到一个新词，则会创建一个新的PE\n- PE的垃圾收集是一个挑战性问题\n    - 超时，内存使用情况\n\nProcessing Node\n- PN是一个逻辑概念\n    - 每个PE都在一个PN上\n    - 一个PN包含多个PE\n- S4的路由是先到PN，再到PE\n- PN到无力节点的映射可以修改，因此可以容错\n- 利用Zookepper保存全局信息，协调节点的行为\n\n![](https://www.xr1228.com//post-images/1582163462684.PNG)\n\nS4的编程模型\n```java\nprivate void processEvent(Eventevent ){\n    queryCount+;\n}\npublic void output(){\n    String query = (String)this.getKeyValue().get(0);\n    persister.set(query.queryCount);\n}\n```\n\n```xml\n<bean id=\"queryCounterPE\" class=\"com.company.s4.processor:QueryCounterPE\">\n<property name=\"keys\">\n    <list>\n        <value>QueryEvent queryString</value>\n    </list>\n</property>\n<property name=\"persister\" ref=\"externalPersister\">\n<property name=\"outputFrequencyByTimeBoundary\" value=\"600\"/>\n</bean>\n```\n\n\n# 六、流计算最主流的框架 —— Storm\n\n## 6.1 Storm的实现\n- Tuple（Named list of values）：[:name \"Chen\" :age 40],类似<KEY,VALUE>\n- Storm的基本概念\n    - Stream : Tuple格式的数据流\n    - Spout ：Stream的源头。\n    - Bolt : 类似于Worker，主要的处理单元。\n        - Filters 流的分析筛选\n        - Aggregation  统计，聚合\n        - Joins 将两个流合并\n        - 访问数据库\n        - 运行自定义函数\n    - Topology ： Storm程序被称为Topology\n-  数据类型：Storm已经支持所有的primitive type，用户也可以自己定义对象作为value。\n-  数据连接（Stream Grouping）：Bolts之间相关连接\n    -  Shuffle Grouping 随机\n    -  Field Grouping 根据tuple field的值选取\n    -  All Grouping 发给所有任务\n    -  Global Grouping 发给具有最小id的任务\n\n定义Strom结构的粒子\n```java\nTopologyBuilder builder = new TopologyBuilder();\nbuilder.setSpout(\"words\",new TestWordSpout(),10);\nbuilder.setBolt(\"exclaim1\",new ExclamationBolt(),3).shuffleGrouping(\"words\");\nbuilder.setBolt(\"exclaim2\",new ExclamationBolt(),2).shuffleGrouping(\"exclaim1\");\n//TestWordSpout()\npublic void nextTuple(){\n    Utils.sleep(100);\n    final String[] words = new String[] {\"nathan\",\"mike\",\"jackson\",\"golda\",\"bertels};\n    final Random rand = new Random();\n    final String word = words[rand.nextInt(words.length)];\n    _collector.emit(new Values(word))；\n}\n// ExclamationBolt()\npublic void execute(Tuple tuple){\n    _collector.emit(tuple,new Values(tuple.getString(0)+\"!!!!\"));  //emit的原因是为了后续容错，后面的ack方法使程序知道execute完成了。\n    _collector.ack(tuple);  \n}\n\npublic void declareOutputFields(OutputFieldsDeclarer declarer){\n    declarer.declarer(new Fields(\"word\"));\n}\n```\n\n实现WordCount的 Storm代码实例\n\n```java\npublic static class WordCount implements IBasicBolt{\n    Map<String,Integer> counts = new HashMap<String,Interger>();\n    public void prepare(Map conf,TopologyContext context){\n        //\n    }\n    public void excete(Tuple tuple,BasicOutputCollector collector){\n        String word = tuple.getString(0);  //bolt中包含多个词的计数，先找到某个词的count，取出增加计数后，在重新写入bolt。\n        Integer count = counts.get(word);\n        cont ++ ;\n        conts.put(word,count); \n        collector.emit(new Values(word,count));\n    }\n    public void cleanup(){\n        //\n    }\n    public void declareOutputFields(OutputFieldDeclarer declarer){\n        declarer.declare(new Fields(\"word\",\"count\"));\n    }\n}\n\n运行Storm\n```java\nLocalCluster cluter = new LocalCluster();\nMap conf = new HashMap();\nconf.put(Config.TOPOLOGY_DEBUG,true);  //Debug模式\n\ncluster.submitTopology(\"demo\",conf,builder.createTopology());\n```\n\n## 6.2  Storm的容错\n- 消息的完整处理\n    - 每一条消息至少执行一次 at least once\n    - 通过每条消息 ack()  方法来判断是否完成，如果部分任务没有完成（Timeout）则判断消息没有完整性。为了防止重新计算带来了状态额不一致，采用Transcational（区分计算和提交部分，提交部分按编号传行，计算部分流水线并行）\n\n\n## 6.3 S4和Storm的对比\n\n- 编程模型\n    - S4更简单，编写每个Key的行为就行了\n    - Storm需要保存和处理更多的东西\n- 推还是拉\n    - S4推，如果缓冲区不够消息就会丢失\n    - Storm拉，因此丢失的消息来自最初的数据输入\n- 容错\n    - S4不管消息丢失，但是可以恢复状态\n    - Storm保证消息被处理至少一次\n- 社区\n    - Storm是Apache顶级项目，社区非常活跃，Twitter使用\n    - S4是Apache incubator项目（孵化器），Yahoo使用\n\n\n\n\n\n\n\n\n\n\n",
      "data": {
        "title": "【工业与大数据】流处理 —— 云计算的重要处理模式",
        "date": "2020-02-19 19:28:16",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/gong-ye-yu-da-shu-ju-liu-ji-suan-yun-ji-suan-de-chong-yao-chu-li-mo-shi.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "gong-ye-yu-da-shu-ju-liu-ji-suan-yun-ji-suan-de-chong-yao-chu-li-mo-shi"
    },
    {
      "content": "\n# 一、NoSQL运动与Cassandra：\nNoSQL(NoSQL = Not Only SQL )，意即\"不仅仅是SQL\"。NoSQL一词最早出现于1998年，是Carlo Strozzi开发的一个轻量、开源、不提供SQL功能的关系数据库。2009年，Last.fm的Johan Oskarsson发起了一次关于分布式开源数据库的讨论，来自Rackspace的Eric Evans再次提出了NoSQL的概念，这时的NoSQL主要指非关系型、分布式、不提供ACID的数据库设计模式。\n2009年在亚特兰大举行的\"no:sql(east)\"讨论会是一个里程碑，其口号是\"select fun, profit from real_world where relational=false;\"。因此，对NoSQL最普遍的解释是\"非关联型的\"，强调Key-Value Stores和文档数据库的优点，而不是单纯的反对RDBMS。\n\n- NoSQL的技术特征\n    - 否定关系模型\n    - 否定ACID事务\n    - 否定SQL语言（某种程度上又回归SQL）\n\nNoSQL主要可以分为三类\n-   Document（文档）：Clusterpoint，Apache CouchDB，Couchbase，MarkLogic，MongoDB\n-   Key-value（键值）：Dynamo，Cassandra，FoundationDB，MemcacheDB，Redis，Riak，Aeropike\n-   Grap（图）：Allegro，Neo4J，InfiniteGraph，OrientDB，Virtuoso，Stardog\n\n## 1.1 Cassandra \n\n![](http://doc.xr1228.com//post-images/1582083836313.PNG)\n\n- Apache Cassandra 是一套开源的分布式NoSQL数据库系统\n- Facebook 开发，用来提升收件箱搜索的特性\n- 2008年7月在Google code上开源\n\n- Cassandra特点与定位\n    - 无单点故障\n    - 高可用性\n    - 可配置的一致性\n- Cassandra使用场景：适合时间追踪与分析\n    - 时间序列数据\n    - 传感器设备数据\n    - 社交媒体分析\n    - 风险分析\n    - 故障分析\n\n\n# 二、Cassandra数据模型\n\nCassandra数据模型借鉴了google Bigdata的数据模型：\n-   键空间 - Keyspace：最上层的命名空间，通常是一个应用程序一个Keyspace， **~=database**\n- 列族 - ColumnFamily：和table并不一样，因为Column Family是稀疏的表\n- 行 Row： 每一行由一个key唯一标示，由columns组成\n- 列 Column：存储的基本单元，它是一个三元组（name，value，timestamp）\n\n![](http://doc.xr1228.com//post-images/1582084090409.PNG)\n\n![](http://doc.xr1228.com//post-images/1582084216424.PNG)\n\n# 三、Cassandra回归SQL的理由\n简单的丢弃SQL极大影响了编程效率\n- Thrift接口\n    - 低层接口：get，get_slice,mutate ....\n    - 直接暴露了内部存储结构（不利于系统升级）\n- CQL2不支持行操作\n- CQL3通过采用复合类型，将KV存储映射到一个更自然的行和列方式表示\n\n ```sql\n  CREATE keyspace testsp WITH replication = {\n      'class':'SimpleStrategy','replication_factor':1\n  };\n  USER testsp;\n  DESCRIBE keyspace testsp;\n  CREATE ColumnFamily users1(id int,user_name varchar,PRIMARY KEY(ID));\n  INSERT INTO users1(id,user_name)Values(1,'abc');\n  UPDATE USERS SET user_name = '2025' WHERE id = 1;\n  DELETE FROM users WHERE id =1 ;\n  SELECT * FROM users1 ;\n  ```\n可以看出目前Cassandra的语法与SQL非常类似\n\n# 四、Cassandra 系统架构\n\n## 4.1 分布式接口\n- Cassandra 采用P2P分布式架构\n    - 所有节点在结构上是**对等**关系\n- Cassandra任一节点**宕机**\n    - 可能对整个集群的吞吐性能造成潜在的影响\n    - 不会造成灾难性的服务中断\n- Cassandra扩展能力强\n    - 集群扩展时，绝大多数步骤都是自动完成的\n    - 得益于P2P的架构，集群的扩展想必**主从结构更**为便捷\n    - \n## 4.2 不同节点的相互感知 —— 流言协议（Gosspi协议）\n在Hadoop这种主从架构的系统中，所有数据节点定期与主节点通讯。所以主从架构中管理节点比较容易。由于cassandra的P2P架构与主从架构不同，在管理集群节点需要特殊技术，那么P2P架构如何管理节点。\n\n  Cassandra借鉴了Amazon的键值系统Dynamo的体系架构，节点利用Gossip协议来发现集群中其他节点的位置（如路由表、Hash环上的位置）、状态（如版本，负载，死活）等信息\n- 流言协议也被成为”Epidemic Algorithms“（疫情算法）：一个节点一旦获得了另一个节点的信息，它就将信息传给所有节点。\n\n- Gossip交换信息的三种模式\n    - 推模式（Push）\n    - 拽模式（Pull）\n    - 推+拽模式（Push - Pull）\n    - Cassandra Gossip协议选用了第三种模式 \n        - 发起者周期性地随机选择一个节点（朋友节点），并初始化一个与它的gossip会话\n            1. gossip 发起者向朋友节点发送GossipDigestSynMessage\n            2. 这个朋友节点接收到该信息后，返回GossipDigestAckMessage\n            3. 发起者接收到朋友节点的ACK消息后，向朋友节点发送 GossipDigestAck2Message\n\n# 五、一致性哈希与数据切分\n\n- 一致性哈希的基本思想\n    - 用同样的哈希函数来计算数据对象和节点的哈希值\n    - 哈希对象不只是数据，还有节点\n- 节点不再是影响书记对象哈希值的参数，而是作为哈希值的参数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "data": {
        "title": "【工业与大数据】NoSql——Cassandra 键值存储系统",
        "date": "2020-02-19 11:28:52",
        "tags": [],
        "published": true,
        "hideInList": true,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "gong-ye-yu-da-shu-ju-da-shu-ju-de-shu-ju-ge-shi-jian-zhi-cun-chu-xi-tong"
    },
    {
      "content": "-- 1 清空临时表,清空后注意提交\n```sql\ndelete EQP_ALARM_MST_PP_TEMP\n```\n-- 2 用excel生成的代码 插入到临时表\n\n\n-- 3 判断临时表中是否有重复数据\n```sql\nselect count(distinct t.EQP_MODULE_ID ||t.EQP_DCP_ID || t.ALARM_ID) from EQP_ALARM_MST_PP_TEMP t \nselect count(t.EQP_MODULE_ID ||t.EQP_DCP_ID || t.ALARM_ID) from EQP_ALARM_MST_PP_TEMP t\n```\n\n-- 4 如果有重复数据  删除临时数据  提交\n```sql\ndelete from EQP_ALARM_MST_PP_TEMP T\n where (t.EQP_MODULE_ID, t.EQP_DCP_ID, t.ALARM_ID) in\n       (select EQP_MODULE_ID, EQP_DCP_ID, ALARM_ID\n          from EQP_ALARM_MST_PP_TEMP\n         group by EQP_MODULE_ID, EQP_DCP_ID, ALARM_ID\n        having count(*) > 1)\n   and rowid not in (select min(rowid)\n                       from EQP_ALARM_MST_PP_TEMP\n                      group by EQP_MODULE_ID, EQP_DCP_ID, ALARM_ID\n                     having count(*) > 1)\n```\n\n-- 5 将临时数据表merge 到目标表\n\n--方法1\n```sql\nINSERT INTO EQP_ALARM_MST_PP\n  SELECT *\n    FROM EQP_ALARM_MST_PP_TEMP t\n   where not exists (SELECT 1\n            FROM EQP_ALARM_MST_PP\n           where EQP_ALARM_MST_PP.EQP_MODULE_ID = t.EQP_MODULE_ID\n             and EQP_ALARM_MST_PP.EQP_DCP_ID = t.EQP_DCP_ID\n             and EQP_ALARM_MST_PP.ALARM_ID = t.ALARM_ID)\n```\n--方法2\n```sql\nMerge into EQP_ALARM_MST_PP G\nusing (select * from EQP_ALARM_MST_PP_temp) NG\non (G.EQP_MODULE_ID = NG.EQP_MODULE_ID \nand G.EQP_DCP_ID = NG.EQP_DCP_ID \nand G.ALARM_ID = NG.ALARM_ID\n)\nwhen not MATCHED THEN\nINSERT (RAWID,EQP_MODULE_ID,EQP_DCP_ID,ALARM_ID,ALARM_CODE,ALARM_TEXT,ALARM_TYPE,USED_YN,SEVERITY_CD,SEND_YN,FIRST_YN,SUBEQP_RAWID,DESCRIPTION,CREATE_DTTS,CREATE_BY,LAST_UPDATE_DTTS,LAST_UPDATE_BY,EQP_ID,SOURCE_ID)\nVALUES (NG.RAWID,NG.EQP_MODULE_ID,NG.EQP_DCP_ID,NG.ALARM_ID,NG.ALARM_CODE,NG.ALARM_TEXT,NG.ALARM_TYPE,NG.USED_YN,NG.SEVERITY_CD,NG.SEND_YN,NG.FIRST_YN,NG.SUBEQP_RAWID,NG.DESCRIPTION,NG.CREATE_DTTS,NG.CREATE_BY,NG.LAST_UPDATE_DTTS,NG.LAST_UPDATE_BY,NG.EQP_ID,NG.SOURCE_ID)\n```",
      "data": {
        "title": "【代码仓库】SQL -- 数据批量插入",
        "date": "2020-02-14 11:37:01",
        "tags": [
          "SQL",
          "代码仓库"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/dai-ma-cang-ku-sql-shu-ju-pi-liang-cha-ru.jpg",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "dai-ma-cang-ku-sql-shu-ju-pi-liang-cha-ru"
    },
    {
      "content": "MapReduce作为大数据技术最主流的并行计算方案，仍然存在编程实现较为复杂（麻烦但不难），性能较差的问题。MapReduce在运算过程中会产生大量的IO操作。为了提高性能，我们引入内存计算的概念。\n<!-- more -->\n\n# 一、背景\n\n### 1.1 并行计算中的局部性\n\n![](http://doc.xr1228.com//post-images/1581930013675.PNG)\n\n矩阵计算过程中，大量的Catch失效消耗了大量的时间，为了解决这个问题，人们提出了分块运算的思想，我们后面进行详细介绍。\n\n### 1.2 高可用性\n- 大数据处理系统通常是由大量不可靠的的服务器组成的的\n- 传统的容错方法不适用\n    - 锁步法，多版本编程\n- 检查点设置与恢复\n\n\n# 二、内存计算技术的必要性\n大数据处理并行系统，最主要就是对以下三个方面进行权衡\n\n- 编程模型 ： 如何识别和描述并行程序\n- 性能/成本优化\n- 容错能力\n\n虽然MapReduce的发明与实现为开创了大数据的新时代，它很好的解决了自动容错，自动负载均衡，并行化处理的问题，但是随着用户对系统提出了更高的要求时，引入过多I/O操作的MapReduce很难支持复杂的，实时的交互式查询。\n\n所以说MapReduce的瓶颈在于大量的IO操作，这些操作产生的大量数据都需要存储在HDFS中。那么如果我们将MapReduce的中间结果存储在内存中，是否就能大幅度提升MapReduce的效率呢？答案是肯定的，这样的方案比之前速度提升10-100倍！\n![](http://doc.xr1228.com//post-images/1582015787498.PNG)\n\n> Distributed memory ：分布式内存\n\n# 三、内存计算的可行性\n\n- 内存是否足够大能够装下所需的数据？   → 现在单台机器数TB RAM的服务器已经很常见\n- 内存有多贵？与硬盘想必性价比如何？  → 摩尔定理\n- 数据保存在硬盘上，可以保证数据的可用性，放在内存里如果容错？\n- 如果高效表示内存里的数据？\n\n![](http://doc.xr1228.com//post-images/1582016119131.PNG)\n\n\n各个内存层次的延迟：DRAM比硬盘块100000倍，但DRAM还是比cache慢6-200\n\n![](http://doc.xr1228.com//post-images/1582016314700.PNG)\n\n> Tape is Dead，Disk is Tape，Flash is Disk，RAM Loacality is king —— Jim Gray \n\n# 四、 SPARK的设计理念\n\n传统抽象多台机器的内存的方案\n- 分布式共享内存（DSM）\n    - 统一地址空间\n    - 很难容错\n- 分布式键-值存储（Piccolo，RAMCloud）\n    - 允许细粒度访问\n    - 可以修改数据（MUTABLE)\n    - 容错开销大\n\nDSM和键值对的容错机制\n- 副本或Log\n    - 对数据密集应用来说开销很大\n    - 比内存写要慢10-100倍\n  \n\n  ## 4.1 内存处理设计方案\n\n  - RDD （Resilient Distributed Datasets）\n    - 基于数据集合，而不是单个数据\n    - 由确定性的粗粒度操作产生（map，filter，join等）\n    - 数据一旦产生，就不能修改（immutable）\n    - 如果要修改数据，要通过数据集的变换来产生新的数据集\n    - 高容错性：数据一旦是确定性的产生，并且产生后不会变换\n        - 就可以通过”重复计算“的方法来恢复数据\n        - 只要记住rdd的生成过程就可以了，这样一次log可以用于很多数据，在不出错的时候几乎没有开销\n```Scala\nmessage = textFile(...).filter(_.contains(\"error)).map(_.split('\\t')(2))\n```\n\n\n![](http://doc.xr1228.com//post-images/1582017712946.PNG)\n\n\n# 五、Spark编程技术\n\n- 基于Scala\n    - 类似Java的一种函数语言\n    - 可以在Scala控制台上交互式的使用Spark\n    - 现在也支持Java和Python\n- 基于RDD的操作\n    - Transformation：从现有RDD产生新的RDD\n        - map，reduce，filter，groupBy，sort，distinct，sample ……\n    - Action：从RDD返回一个值\n        - count，collect，first，foreach\n\n### 例子：Log挖掘\n将数据空文件系统中调入内存，然后进行交互式的查询\n```JAVA\nlines = spark.textFile(\"hdfs://...\")\nerror = lines.filter(_startwith(\"error\"))\nmessages = errors.map(_.split('\\t)(2))\ncachedMsgs = messages.cache()  //将其存入缓存\ncachedMsgs.filter(_.contains(\"foo)).count\ncachedMsgs.filter(_.contains(\"bar\")).count\n```\n性能  1TB数据在内存上需要5-7s完成，在硬盘上需要 170s\n\n### 例子：逻辑回归\n```JAVA\nval data = spark.textFile(...).map(readPoint).cache()\nvar w = Vector.random(D)\nfor(i <- 1 to ITERATIONS){\n    var gradient = data.map(p => (1/(1+exp(-p.y*(w dot  p.x))) - 1)*p.y*p.x)\n    .reduce( _ + _ )\n    w -= gradient\n}\nprintln(\"final w: ' +w）\n```\n\n![](http://doc.xr1228.com//post-images/1582018554068.PNG)\n\n### 例子：WorkCount\n\n```JAVA\nvar spark = new SparkContext(master,appName,[sparkHome],[jars])\nvar file = spark.textFile(\"hdfs://...\")\nvar counts = file.flatMap(line -> line.split(\" \"))\n                    .map(word => (word,1))\n                    .reduceByKey( _ + _ )\ncounts.saveAsTextFile(\"hdfs://,,,\"）\n```\n\n- SparkContext 实例化一个spark\n- flatMap 将某一个字段分为多个元素\n    - line = “a b c a” →  （a）（b）（c）（a） → （a，1）（b，1）（c，1）（a，1）\n- reduceByKey → （a，1）（b，1）（c，1）（a，1） → （a，2）（b，1）（c，1）\n  \n\n  # 六、Spark的实现\n\n### 6.1 延迟估值（Lazy Evaluation）\n\n  \n```JAVA\nvar lines = sc.textFile(\"data.txt\")\nval lineLengths = lines.map(s => s.length)\nval totalLength = lineLengths.reduce((a,b) => a + b)\n```\n前两行都不会出发计算（Transformation）\n最后一行的reduce会引发计算，生成DAG\n\n- 复杂的DAG（Directed acyclic grap 有向无环图）\n![](http://doc.xr1228.com//post-images/1582074271042.PNG)\n\n### 6.2 Spark性能优化\n\n#### 6.2.1 数据划分技术\nspark通过数据划分将 links 与\n```java\nlinks = // RDD of (url,neighbors) pairs    url和相邻的网页\nranks = // RDD of (url,rank) pairs   网页的rank\n\n// 通过不断循环，实现配置rank算法\nfor(i <- 1 to ITERATIONS){\n    ranks = links.join(ranks).flatMap{\n        (url,(links,rank)) => links.map(dest => (dest,rank/links.size))\n    }.reduceByKey(_ + _)\n}\n```\n![](http://doc.xr1228.com//post-images/1582074683069.PNG)\n![](http://doc.xr1228.com//post-images/1582074807555.PNG)\n\n#### 6.2.2 Cache\n\n- 对messages使用cache，意思是将后面可能会重用的数据保存起来，并“尽量”放在内存中\n    - 正常计算的时候避免重算\n    - Cache是Persist的特例,是RDD提供的将数据保存在内存的方法\n```java\nlines = spark.textFile(\"hdfs://...\")\nerrors = lines.filter(_startsWith(\"ERROR\"))\nmessages = errors.map(_split('\\t')(2))\ncachedMsgs = messages.cache()\ncachedMsgs.filter(_.contains(\"bar\")).count\n```\nStorageLevel列表\n![](http://doc.xr1228.com//post-images/1582081342943.PNG)\n\n- MEMORY_ONLY 2 表示数据保存两份数据\n\n\n# 七、Spark的生态环境\n![](http://doc.xr1228.com//post-images/1582081795189.PNG)\n\n- Spark 是伯克利大学AMP实验室开发的大数据系统\n- Mesos ： 底层资源管理系统和调度器\n- HDFS ： Hadoop 文件管理系统\n- Tachyon ： 内存文件系统\n- Spark ： 内存计算框架\n- Shark ： Spark支持SQL API\n- Spark Streaming ： Spark支持流计算\n- GraphX ： Spark 支持图算法与模型\n- MLbase ： Spark 支持机器学习\n\n\n现在的大数据系统，MapReduce是通用的批处理系统，而其他的工具用于实现专门业务的专用系统，例如Pregel，Giraph，Dremel，Drill，Tez，Impala，GraphLab，Strom，S4。而Spark系统希望将MapReduce一般化（任务DAG和数据共享）并统一编程框架。\n然而Spark仍有局限性，Spark进行例如BFS（图遍历）算法过程中每次进行细粒度更新时，无法对RDD内部进行编辑，需要更换新的RDD。从而发生大量无用的内存拷贝，也产生了大量无用数据，导致性能的问题。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "data": {
        "title": "【工业与大数据】内存计算的解决方案 —— Spark",
        "date": "2020-02-10 09:03:05",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/gong-ye-yu-da-shu-ju-nei-cun-ji-suan-geng-kuai.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "MapReduce作为大数据技术最主流的并行计算方案，仍然存在编程实现较为复杂（麻烦但不难），性能较差的问题。MapReduce在运算过程中会产生大量的IO操作。为了提高性能，我们引入内存计算的概念。",
      "fileName": "gong-ye-yu-da-shu-ju-nei-cun-ji-suan-geng-kuai"
    },
    {
      "content": "大数据作为一门应用广泛的技术，在不同的应用场景下对其数据结构，处理实时性都有不同的需求，所以大数据技术的先驱们开发了许多不同的技术框架来满足不同的需求。本章主要介绍大数据所采用的的主流处理框架以及其技术细节。\n<!-- more -->\n\n\n- 大数据处理工具分类\n  ![](http://doc.xr1228.com//post-images/1581042442307.PNG)\n\n\n# 一、几个重要的概念\n\n### 大数据技术的几个重要的观点，这个也是贯穿在整个大数据技术的重要思想\n\n- 分布式：数据存储于成百上千个服务器中\n- 大数据块：大数据块减少元数据的开销\n- 失败无法避免：使用商用硬件 → 失败是不可避免的，所以买便宜的硬件\n- 简洁的才是稳定的：简洁的一致性模型（单写者，避免相互等待）\n\n\n### 数据并行化（DLP）\n- 若干硬盘上的大量数据，可以被并行化的操作（比如，操作文档） Embarrassingly Parallel\n\n这是什么意思呢？将数据分隔成不同的，相互无关的数据块就能实现数据并行化。我们举个例子：\n\n**词频统计**   从多个数据中找到dog的发生次数，我们只需要把数据分成不同的块，同时进行查找，没找到一个dog，就返回一次结果。这样就能显著提高查找效率，这也是一种很朴实的观点。\n\n![](http://doc.xr1228.com//post-images/1581043388967.PNG)\n\n但是这样的解决方案也衍生了两个问题：\n- 共享的状态\n    - 吞吐量（多个进程同时改变）\n    - 同步（同时修改需要锁）\n- 小粒度的通信让元数据管理变得复杂\n\n为了解决这样的问题，我们将每个数据块看做一个单元，每个单元全部数完后将结果一次性返回。\n看似很美好，但是又又又衍生出两个问题：\n\n- 失败的机器（某个机器发生错误无法及时发现异常）\n- 共享的状态太大（返回的数据量太大）\n\n所以我们将全局状态也作为分布式状态，并且将每个数据块的存储状态保存下来。这样就满足了分布式处理的需求。\n![](http://doc.xr1228.com//post-images/1581059591932.PNG)\n\n> 以上提到的设计理念，就是MapReduce的设计理念。接下来我将对MapReduce进行详细介绍。\n\n# 二、MapReduce\n\n### MapReduce Process —— 数据并行的分治策略\n- Map\n    - 将数据分割为shards或者splites，将它们分配给工作节点，将工作节点来计算子问题的解。\n- Reduce\n    - 收集，合并子问题的解\n- 易于使用\n    - 开发者可以集中解决数据处理的问题\n    - MapReduce系统负责解决其他细节\n  \n  > MapReduce是很早就提出的想法，是算法设计中常用的策略。但是其技术特点非常符合大数据的技术需求，很好的解决了大数据系统的需求，让开发者集中精力进行数据处理，而不用考虑数据内部的细节。\n\n  ### MapReduce 的基本编程模型\n\n- Map\n    - map（in_key，in_value） → list（out_key,intermediate value)\n        - 处理输入的键值对\n        - 生成中间结果集\n- Reduce\n    - reduce(out_key,list(intermediate_value)) → list(out_value)\n        - 对于某个键，合并他所有的值\n        - 生成合并后的结果值集合 \n\n例子： 词频统计\n\n![](http://doc.xr1228.com//post-images/1581060446962.PNG)\n\nMapReduce算法的程序实现是非常简洁的\n\n```C\nmap(String input_key,String input_value):\n    //input_key:document name\n    //input_value:document contents\n    local Count = CountLocally(input_value);\n    foreach count:\n        Emit(word,count); //Produce count of words\n\nreduce(String word,Iterator intermediate_values):\n    //word:the word(in the intermediate key);\n    //intermediate_value:a list of counts;\n    int result = 0;\n    for each v in intermediate_values;\n        result += v;\n    Emit(word,result);\n```\n\n![](http://doc.xr1228.com//post-images/1581060926629.PNG)\n\n### MapReduce 的执行步骤\n\n1. 将输入数据分隔成M块，在每块上分布式的调用map()\n    - 通常每个数据魁岸16MB或者64MB\n    - 取决于GFS的数据库大小\n2. 输入数据由不同的服务器并行处理\n3. 通过将中间结果分割成R块,对每块分布式的调用Reduce()\n\n- M和R的数量由用户指定\n    - M>>#servers,R>#servers\n    - 很大的M值有助于负载均衡,以及快速恢复\n    - 每个Reduce()调用,对应一个单独的输出文件,若依R值不应该太大\n\n![](http://doc.xr1228.com//post-images/1581061621076.PNG)\n\n![](http://doc.xr1228.com//post-images/1581061663957.PNG)\n\n\n### Map Recude的性能优化\n\n- MapReduce 冗余执行\n    - 整个任务完成时间是由最慢的节点决定的\n    - 解决方案:在接近结束时,生成冗余任务 → 用其他机器同样进行冗余任务\n        - 谁最先完成,谁获胜\n        - 也叫做\"投机\"(speculative)执行\n    - 影响:极大的缩短任务完成时间\n        - 资源消耗增加 3%,大型任务速度提高 30%\n\n> MapReduce所有的操作都是独立且幂等的,所以不存在同步性问题\n\n- MapReduce故障处理\n    - 计算节点故障\n        - 控制节点通过周期性的心跳来检测故障\n        - 重新执行\n    - 主节点故障\n        - 可以解决,但是目前还没有解决(控制节点故障可能性很低,所以就直接重启即可)\n    - 健壮性\n        - MapReduce论文报告:曾经丢失1800个节点中的1600个,但是任务仍然正确完成.\n\n## Hadoop ：MapReduce的开源实现\n\n### Hadoop MapReduce的基本架构\n\n> Hadoop不仅仅实现了文件分布式存储和MapReduce，还实现了一系列容错、资源远离等服务\n\n- JobTracker（Master）\n    - 接收MR作业\n    - 分配任务给Worker\n    - 监控任务\n    - 处理错误\n- TaskTracker（worker）\n    - 运行Map和Reduce任务\n    - 管理中间输出\n- Client\n    - 提交作业的界面\n    - 得到多样的状态信息\n- Task\n    - 一个独立的过程\n    - 运行Map/Reduce函数\n\n\n### Hadoop MR程序执行过程 1\n\n![](http://doc.xr1228.com//post-images/1581090883921.png)\n\n![](http://doc.xr1228.com//post-images/1581093484533.png)\n\n\n![](http://doc.xr1228.com//post-images/1581093664775.png)\n\n\n## MapReduce总结\n\n### MapReduce的理解要点\n- 同样的细粒度操作（Map&Reduce）重复作用于大数据\n- 操作必须是确定性的\n- 操作必须是幂等的，才没有副作用\n- 只有shuffle过程中才有通信\n- 操作（Map&Reduce）的输出存储于硬盘上\n\n### MapReduce的作用\n- Google\n    - 为Google Search建立索引\n    - 为Google News进行文章聚类\n    - 统计行的机器翻译\n- Yahoo！\n    - 为Yahoo！Search建立索引\n    - 为Yahoo！Mail进行垃圾检测\n- Facebook\n    - 数据挖掘\n    - 广告优化\n    - 垃圾检测\n\n### MapReduce优点\n- 分布式过程完全有名\n    - 没有一行分布式编程（方便，有保证正确性）\n- 自动的容错性\n    - 操作的确定性保证了故障的任务可以在其他地方再次运行\n    - 保存的中间结果保证了只需要重新运行故障reduce节点\n- 自动的规模缩放\n    - 由于操作是没有f副作用的，所以他可以动态的被分发到任何数量的机器\n- 自动的负载均衡\n    - 及时移动任务，投机性的执行慢的任务\n  ### MapReduce缺点\n  1. 及其严格的数据流\n  2. 很多常见的操作也必须手写代码\n  3. 程序语义隐藏在map-reduce函数中：自动的维护，扩展，优化都比较困难\n\n\n# 三、PIG LATIN 编程语言\n\n> PIG LATIN本意是英语中一种“黑话”的规则，其规则就是将单词首字母放置在最后并加上ey，比如“happy” ➡️ “appy-hey” \n\n在大数据技术中，PIG LATIN是一种高于MapReduce的可以处理任意数据流的大数据处理系统（也是一种语言）。\n\n为了说明PIG LATIN的作用，我们可以举个例子\n\n![](http://doc.xr1228.com//post-images/1581146546078.png)\n\n为了解决这个需求，传统的SQL 需要将两个表 Join在一起，再通过Group by，count的方式进行查询。但是显而易见，在互联网中这两个表可能是非常非常非常大的，他们只能被分布式的存储在不同的机器中，那么如何进行查询和运算呢？\n\n![](http://doc.xr1228.com//post-images/1581146799512.png)\n\n如果通过MapReduce进行运算，则需要将不同的MapReduce结合起来多次运算，最主要的MapReduce需要参数具有相同的数据类型，我们可能还涉及到数据类型的转换，这样就产生了大量的代码，也很难进行维护\n\n![](http://doc.xr1228.com//post-images/1581146968591.png)\n\n因此，Yahoo！发明了PIG LATIN语言。\n\n- 更高级的编程语言\n    - 更快捷的MapReduce工作流程\n    - 提供关系型数据库操作（例如JOIN，GROUP BY）\n    - 可以方便地潜入JAVA函数\n- 最先在Yahoo！Research使用\n    - 当是运行Yahoo！大约50%的任务\n\n## 3.1 PIG LATIN的基本语法\n\n```PIG LATIN\nvisits = load '/data/visits' as (user,url,time);\ngVisits = group visits by url;\nvistCounts = foreach gVisits generate url,count(visits);\n\nurlInfo = load '.data.urlInfo' as (rul,categroy,pRank);\nvisitCount = join visitCounts by url,urlInfo by url ;\n\ngCategories = group visitCounts by category;\ntopUrls = foreach gCategories generate top(vistCounts,10);\n\nsotre topUrls into 'data/topUrls';\n```\n\n嵌套的数据结构\n\n- Pig Latin采用完全可以嵌套的数据结构\n    - 原子值（Atomic Values），元组（tuples），包（列表，bages（lists）），映射（maps）\n\n![](http://doc.xr1228.com//post-images/1581148734773.png)\n\n- 优势\n    - 对于开发者，比数据库的扁平组（flat tuple）更自然\n    - 避免代价昂贵joins操作\n\n- 嵌套数据模型\n    - 解耦grouping操作作为一个独立的操作\n  ![](http://doc.xr1228.com//post-images/1581148988714.png)\n    - 共同分组（CoGroup） 性能优化\n  ![](http://doc.xr1228.com//post-images/1581149076178.png)\n\n## 3.2 Pig Latin的实现与优化\n\n User ➡️ PIG（或者写SQL）➡️Hadoop Map-Reduce ➡️cluster\n\n Pig Latin 翻译为 Map-reduce的方法\n- 每一个group或join操作形成一个MapReduce\n- 其他操作进入map和reduce阶段的流水线\n\n![](http://doc.xr1228.com//post-images/1581149506733.png)\n\n- 抽象的优势\n    - 抽象的程序更简单，计算机可以进行优化\n    - 可以逐渐优化，不影响用户使用\n![](http://doc.xr1228.com//post-images/1581149584250.png)\n\n- Pig Latin的优化\n    - 合并函数（combiner）\n        - 中间过程传递数据越少越好，聚合求和运算越早执行越好\n        - 聚合函数\n        - 去掉重复数据（distinct）\n        ![](http://doc.xr1228.com//post-images/1581149915655.png)\n    - 偏斜数据的链接（Skew Join）\n        - 如果很多值都有同样的健，就会有问题\n        - Skew join对数据进行采样，来找到高频值\n        - 在reducer中进一步分割这些数据\n        - 转化为map-oinly的任务\n            - 将很小的数据集作为旁路输入（“sid file”）\n    - 多数据流：PIG通过split将Map分为多个数据流，减少Reduce操作\n\n# 四、其他类似框架\n\n- Sawzall\n    - 基于MapReduce的数据处理语言\n    - 严格的结构：过滤➡️聚合\n- Hive\n    - 基于MapReduce的类似SQL的语言\n- DryadLINQ\n    - 基于Dryad的类似SQL的语言\n\n# 五、总结\n\n- Hadoop与PIG\n![](http://doc.xr1228.com//post-images/1581150296782.png)\n- Hadoop 生态系统\n![](http://doc.xr1228.com//post-images/1581150412879.png)\n\n- 另一面：“MapReduce： A major step backwards”\n    - David J.DeWitt,Michael Stonebraker\n    - 在编程模式中后退了一大步\n        - 没有模式，没有高级的访问语言\n    - 一个次优化的实现\n        - 它使用了暴力法搜索，而不是用任何索引\n    - 一点也不创新\n        - 25年前就有类似的技术\n    - 缺少了目前数据库管理系统一般都有的大多数特点\n        - 索引，更新，食物，完整性约束，逻辑视图\n<!-- more -->\n",
      "data": {
        "title": "【工业与大数据】大数据的主要处理框架与工具",
        "date": "2020-02-07 10:18:09",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/gong-ye-yu-da-shu-ju-da-shu-ju-de-zhu-yao-chu-li-kuang-jia-yu-gong-ju.jpg",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "大数据作为一门应用广泛的技术，在不同的应用场景下对其数据结构，处理实时性都有不同的需求，所以大数据技术的先驱们开发了许多不同的技术框架来满足不同的需求。本章主要介绍大数据所采用的的主流处理框架以及其技术细节。",
      "fileName": "gong-ye-yu-da-shu-ju-da-shu-ju-de-zhu-yao-chu-li-kuang-jia-yu-gong-ju"
    },
    {
      "content": "为什么传统的NFS/AFS并不能满足大数据的需要？为什么GFS大名鼎鼎？它解决了什么样的问题？\n<!-- more -->\n# 一、Google文件系统\n\n- 为什么需要一个不同的分布式文件系统？\n    - 为了建立搜索引擎，需要存储互联网容量的数据，支持数据快速写入到分布式文件系统中\n    - 为了支持查询，需要对大量数据进行处理，需要建立**倒排索引**，需要对网页数据进行排序\n    - 所有的技术革新，都是业务驱动的，业务需求决定了Google 文件系统的开发\n\n- GFS中的具体需求\n    - 需要一个分布式文件系统能够存储大量的数据\n        - 这样的文件系统建立在大规模X86集群之上，这些节点是廉价的，并且系统的模块还会出错\n    - 现有的文件系统无法满足Google对于存储数据的需求\n        - 整个硬件中的许多模块会出现出错的情况，出错会同时发生\n        - 有大量的超大规模文件（多个网页合并成的大数据文件），文件大小会超过数百G\n    - 读写模式（优化考虑）：\n        - 文件系统读写大量是写入一次，多次读取的特性\n        - 写入并发，并发读取\n        - 延迟和带宽的考虑（高延迟，高带宽）\n\n# 二、如何设计Google文件操作系统\n\n- 几个目标\n    - 要做一个文件系统（目录树，文件读写），支持读写非常大的文件\n    - 充分利用资源（负载均衡，扩展性）\n    - 容错（不能因为少数的节点出错就停止工作）\n    - 系统简洁（复杂的系统在涉及到数千个节点的时候无法理解与控制）\n\n\n为了实现以上目标，Google给出了文件系统设计的基本设计：\n- 文件系统的基本设计\n    - 数据块：由于文件的规模十分庞大，文件将会被划分为多个大小为64MB的数据块进行存储，这个数据块的大小远远大于一般文件系统数据块的大小（64K）\n    - 性能设计：依据全局动态信息，自动调整数据在不同服务器中的存放，服务器存储利用率相似，负载动态调整\n    - 可靠性：为了保证数据的可靠性，数据通过副本的方式保存在多个节点中，一般保存在3个节点以上\n    - 系统设计简化：通过单个节点保存文件系统的元数据，这个节点被称为Master节点，主借点来协调整个系统的访问流程。\n\n\n# 三、分布式文件系统的设计\n![](http://doc.xr1228.com//post-images/1580957028720.PNG)\n\n- 文件系统的主节点（存储元数据）\n- 文件系统命名空间：将文件路径与chunk对应信息保存（chunkServer） \n- 应用程序发送请求后，Master节点返回chunkhandle，chunklocations的信息，应用程序根据以上信息访问对应服务器。\n\n# 四、GFS性能问题\n\n根据之前的设计，我们很明容易就能发现这样的文件系统可能会存在两个问题：\n- 所有的访问都会通过Master节点，可能会成为性能瓶颈\n- master节点发生异常后整个文件系统都会出现异常\n\n为解决以上问题：\n- 主服务器的性能负载问题（主要的问题）\n    - 客户端数据缓存，每次请求获取1000chunk的元数据，减少客户端与元数据信息交互\n    - 元数据服务器存储在内存中\n- 块服务器的负载均衡问题 \n    - 不能让一部分块服务器出现性能瓶颈 （chunkServer）\n    - 负载必须要进行动态调整\n- 块服务器的扩展性问题\n\n> 在GFS中，一个64M的数据块大约需要64B元数据。10PB数据约需要 10GB的元数据控件（很容易可以满足）\n\n# 五、GFS可靠性问题\n\n- 块服务器的可靠性问题\n    - 快服务器出现错误怎么办？ → master服务器发现块服务器不在线时，启动副本恢复\n    - 一个块服务器出现错误的时候，副本数目恢复所需要的时间 （不同的数据块从不同服务器并行恢复）\n- 主服务器的可靠性问题\n    - 内存数据的可恢复性（日志操作，快速恢复，定期硬盘快照）\n    - 单个节点主服务器的可恢复性 → 影子（shadow）服务器\n    - 影子节点仍然会出现错误 → 硬盘快照保存多个副本\n\n# 六、 GFS一致性要求\n- 三副本一致性的基本要求\n    - 目标：维持每一个数据块的三个副本完全一样\n    - 方法：出事数据块都没有数据，出事数据相同，之后以相同的操作顺序执行客户端的操作\n    - 手段：基于租期以及主要副本的顺序定义\n\n![](http://doc.xr1228.com//post-images/1580972371396.PNG)\n\n- GFS中写入操作对一致性的影响\n\n![](http://doc.xr1228.com//post-images/1580972774298.PNG)\n\n- GFS 放松的一致性\n    - 一致的（Consistent）：文件的三个副本一直\n    - 明确的（Defined）：反映了客户端的操作\n\n\n# 七、GFS的POSIX兼容性\n\n> GFS不是标准的文件系统，是建立在本地文件系统之上的应用层文件系统。GFS与标准的POSIX文件系统并不兼容，因此GFS上不能够运行程序，访问GFS需要一个客户端。\n\n- 在数据的读写上，GFS的POSIX不一致主要表现在以下两个方面：\n    - 数据读写： GFS增加了Append操作，由文件系统确定写入地址，这是POSIX所没有的\n    - 数据一致性：POSIX不兼容，GFS定义了自己的数据一致性模型\n\n> 兼容性哲学：通用的一般不是最优的策略\n\n# 八、GFS的垃圾收集\n\n- 垃圾收集\n    - 删除的数据不是直接从本地文件系统中删除，而是通过垃圾收集的方法，比传统的方法简单，并更加可靠\n    - 主服务器要日志记录删除操作，并将文件改名成隐藏的文件名\n    - 在系统负载不高的时候后台挥手隐藏的文件\n- 过期副本的删除\n    - 整个系统在节点失效，并重新加入的时候产生过期副本数据\n    - 通过检查数据库的版本来探测到过期副本\n\n# 总结\n\nGFS实际上是演示了如何在现代市场上可见的硬件水平上构建一个大规模的处理系统\n- 从设计上就内建错误容忍机制\n- 对大文件的优化，特别是数据追加以及读取\n- 不局限于现有的文件系统接口，为了应用进行接口的扩张\n- 尽量使用简化的设计，如单个主服务器single master，简化系统的结构，便于理解与维护\n  \n  GFS以及相关的开源等价软件包括HDFS，MooseFS等限制的部署都非常广泛，验证了这个结构的有效性。",
      "data": {
        "title": "【工业与大数据】GFS：Google文件系统",
        "date": "2020-02-06 10:26:12",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/gong-ye-yu-da-shu-ju-gfsgoogle-wen-jian-xi-tong.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "为什么传统的NFS/AFS并不能满足大数据的需要？为什么GFS大名鼎鼎？它解决了什么样的问题？",
      "fileName": "gong-ye-yu-da-shu-ju-gfsgoogle-wen-jian-xi-tong"
    },
    {
      "content": "## 一、文件系统基础  \n</br>\n\n### 文件系统概述\n#### 为什么要有文件系统？\n需要介质保存一些永久的数据，停电后数据也可以长期保存\n#### 文件系统的名字空间，名字空间的操作\n在文件数节点上进行操作\n#### 文件系统中文件读写操作\n提供一些例如 open、read、write、close的操作函数\n- open 操作：将文件 offset = 0，并记录文件操作信息\n- close 操作：将文件从内存中删除\n- read 操作：从offset=0位置读取size大小的数据。\n  \n### 文件系统的设计\n#### 文件系统的下层接口\n- 磁盘的读写接口，磁盘中的地址\n#### 文件系统的上层接口\n- 文件树的组织\n- 文件数据的读写\n#### 文件系统最本质的功能：将文件名字翻译定位到一个具体的磁盘位置，进而可以完成文件的读写。  \n\n</br>\n\n\n### 文件系统接口标准化\n虚拟文件系统（VFS）是物理文件系统与服务之间的一个接口层，它对Linux的每一个文件系统的所有细节进行抽象，使得不同的文件系统在Linux核心以及系统中运行的其他进程看来，都是相同的。即调用VFS接口来调用不同的文件操作系统。\n</br>\n</br>\n### 文件系统的磁盘数据结构\n![](http://doc.xr1228.com//post-images/1580632535964.png)\n\n### 文件系统的讨论\n- 关于磁盘块大小的讨论\n    - 一个文件起码占用1个文件块的空间（选择磁盘块越小浪费越小）\n    - 每个磁盘块需要元数据进行描述（磁盘块越多，开销越大）\n    - 虽然磁盘物理特性决定了最小的读写单元512字节，但是目前多数文件系统选用4k磁盘块。（根据不同文件系统特点选择）\n\n- 文件系统的缓存\n    - 缓存能够加速的必要条件，时间局部性（经常访问）与空间局部性（附近的数据也需要访问）\n\n- 磁盘系统的优化策略\n    - 磁盘的顺序读写与随机读写：尽量让磁盘进行顺序读写（顺序读写100MB带宽，随机读写1MB带宽）\n    - 如何进行磁盘优化\n\n## 二、分布式文件系统\n\n- 分布式文件系统需要提供什么功能？\n    - 文件系统目录树\n    - 文件的读写\n- 分布式文件系统建立的基础要讨论的两个问题\n    - 是否直接面对磁盘？ \n        - 无需直接面对磁盘，而是使用每台机器的操作系统中的文件系统来操作磁盘\n        -  直接面对磁盘： SANFS 更高性能\n    - 分布式文件系统中的地址是什么？\n        - 无法直接定位到磁盘：先定位到机器，然后定位到磁盘\n\n> 分布式文件系统的本质功能：将一个以目录树表达的文件翻译为具体的节点，而到磁盘的定位则可以交给本地文件系统完成。\n\n## 三、分布式文件系统举例 NFS（网络文件系统）\n\n![](http://doc.xr1228.com//post-images/1580954964552.PNG)\n\n###NFS文件系统的扩展：AFS文件系统\nNFS系统只有一台服务器，通过一台服务器对文件进行定位，用户操作某一个文件时，其实是对Server上某个目录进行操作。\n\n![](http://doc.xr1228.com//post-images/1580955318970.PNG)\n\nAFS是放在广域网的分布式文件系统\n\n1. 当用户访问某个文件时，先访问根服务器 /afs\n2. 根服务器维护了下一级服务器 （pku,tsinghua,washington)\n3. 每一级服务器为用户返回下一级服务器地址\n4. 最后一步交给本地文件系统对具体文件操作\n\n\n\n\n\n\n\n\n\n",
      "data": {
        "title": "【工业与大数据】分布式文件系统",
        "date": "2020-02-02 16:14:41",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/gong-ye-yu-da-shu-ju-fen-bu-shi-wen-jian-xi-tong.jpg",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "gong-ye-yu-da-shu-ju-fen-bu-shi-wen-jian-xi-tong"
    },
    {
      "content": "### 云计算 Cloud Computing\n既指作为服务通过互联网提供的应用程序（SaaS模式），又指提供这些服务的，位于数据中心的硬件和系统软件（公用计算）\n- 云：数据中心硬件与软件\n- 公有云：用即用即付的模式，开放给大众实用的云\n- 私有云：一个企业或者组织内部的数据中心\n- 公用（utility）计算：给人以无限资源的错觉\n  \n（以上定义来自加州大学伯克利分校，RAD实验室，2009年2月）\n\n### 云计算商业模式的三大特点：\n- 按需服务\n- 资源池\n- 可测量的服务\n\n### 云计算发展的市场条件\n- 大规模的互联网应用（社交网络、多媒体）\n    - 规模经济\n    - 需求增长促进数据中心建设增长\n    - 无法预测的应用增长速度Zynga，Netflix\n- 大数据应用\n    - 日志分析\n    - 机器学习应用\n\n### 云计算的价值 ：提高数据资源利用率\n  \n![](http://doc.xr1228.com//post-images/1580138871978.png)\n![](http://doc.xr1228.com//post-images/1580138914955.png)\n\n### 云计算的分类\n根据提供抽象接口位于哪一层来分类\n- 指令集虚拟机（Amazon EC2，3Tera）\n- 运行时系统虚拟机（Microsoft Azure）\n- 框架型虚拟机（Google AppEngine，Force.com)\n- 折衷：灵活性/可移植性 VS “内置”功能\n  \n  ![](http://doc.xr1228.com//post-images/1580139074150.png)\n\n根据提供服务类型分类\n- SaaS 软件即服务 ——消费者使用提供商运行在云设施上的应用程序，基本无法控制程序或者基础架构。\n- PasS 平台即服务 ——消费者将自己编写的程序部署在云基础设施上，可以控制应用程序，但不能控制基础设施\n- IaaS 基础设施即服务 —— 提供处理、存储、网络和其他基础计算资源，消费者可以利用这些资源部署任意程序，包括操作系统或应用程序。\n\nGartner新技术炒作曲线\n\n![](http://doc.xr1228.com//post-images/1580139452341.png)\n",
      "data": {
        "title": "【工业与大数据】云计算的商业模式",
        "date": "2020-01-27 23:10:56",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/yun-ji-suan-de-shang-ye-mo-shi.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "yun-ji-suan-de-shang-ye-mo-shi"
    },
    {
      "content": "\n大数据这个词已经火热了很多年，似乎处处都存在着大数据的噱头，让我们回归本质，探讨一下大数据是什么？\n本文介绍了大数据技术细节以及相关背景的的一些概念。本文并未对大数据的相关知识进行总结，所以本文仅作为参考，无需详细阅读。\n<!-- more -->\n\n\n\n## 背景 为什么需要大数据？\n\n- 我们比以往产生**更多**且**更多样性**的数据\n- 我们比以往**更快的**产生数据\n- 这些数据具有其价值性\n\n针对以上三个基本原因，我们必须通过处理这些数据来提取其中的价值。\n\n然而处理这些大量的数据面临两个问题：\n\n- 大规模数据的存储\n- 大规模数据的分析\n\n这里我们举一个**例子**：早期的网络环境就如同一条小河，依河而居的人们世代通过抓鱼维生。这个时期鱼的数量有限、种类单一。人们只需要把鱼抓起来放到冰箱，想吃的时候直接拿出来烤就可以了。\n\n![](http://doc.xr1228.com//post-images/1579677299293.PNG)\n\n随着人类抓鱼的速度越来越快，抓鱼水平越来越高。人们抓到的鱼数量越来越大，种类越来越丰富。人们逐渐遇到了两个代表性的问题：\n\n- 冰箱放不下（存储不足）\n- 烹饪不过来（处理效率不足）\n\n如何解决这样的问题呢？\n\n1. 冰箱放不下：\n\n解决冰箱放不下无非两个思路。①换一个大一点的冰箱（**纵向扩展**）②多买几个冰箱（横向扩展）\n显然纵向扩展是难以实现的，存10000...条鱼需要多大的冰箱？\n横向扩展相对容易实现，鱼多的时候多买一些冰箱，搞一个冷库（**集群**）然后大家一起去存放鱼（**分布式存储**）\n然而随着冰箱越来越多（**集群规模扩大**），人们又单独做了一个账本（**元数据**），里面存储了每条鱼存放在冰箱什么位置的信息。\n\n2. 烹饪不过来：\n\n鱼越来越多，即使所有的鱼都能保存到冰箱中，但是只有一个厨师的话效率实在太低。\n不如多找几个厨师，大家一起烤（分布式计算）\n## \n所以说，大数据技术本质上用于解决 海量数据提取、存储、处理的一套技术，分布式是其主要实现思路。\n\n## 重要结论\n\n**学术界普遍认为大数据仍处于发展与创新的初始阶段**。大量数据的存储并不是大数据技术的主要问题甚至不是重要问题，非结构化的数据的快速处理与分析利用才是大数据要解决的最主要问题。\n\n**大数据是相对的**，大数据的概念也是不断变化的。（三十年前100M也是大数据）大数据是指用现有技术手段和软件难以快速处理的数据。今天的大数据主要强调数据的非结构性与实时处理的要求。\n\n**人是大数据中重要的环节，数据可视化是实现人的作用的主要工具** 大数据强调人通过数据可视化对大数据运算结果的再次分析与知识提炼，以便进行进一步的数据挖掘。\n\n** 大数据的四个特点：**\n- Volume 数据量大\n- Velocity 速度快\n- Variety 种类多样\n- Value 价值密度低\n\n\n# 一、云计算\n\n## 大数据对于系统架构的需求\n\n为了对应大数据的几个基本特点：Volume(数据量大) Velocity(产生速度快) Variety(种类多)  Value(价值密度低)。因为以上几个特点，大数据对于数据架构的需求如下：\n\n- 显示的需求\n    - 海量计算和存储  ➡️  数据量大\n    - 快速计算  ➡️  产生速度快\n- 隐式的需求\n    - 数据的快速传输  ➡️  产生速度快\n    - 灵活性  ➡️  种类多\n    - 低成本  ➡️  价值密度低\n\n## 大数据的核心设计理念\n\n- 并行化\n    -  并行请求\n    - 并行进程\n    - 并行指令\n    - 并行数据\n    - 硬件描述\n- 规模经济  例子：WSC（仓库规模的计算机） 用网络链接起来的计算和存储设备。实用相对同质的硬件和系统软件平台、共享相同的系统管理、运行相对小数目的超大型程序、通用的资源管理架构增强了灵活性。\n    - 主要部件\n        - 供电、制冷、建筑、网络、安全\n        - 存储、计算\n    - 优势\n        - 规模经济\n        - 提高使用率\n    - 挑战\n        - 能耗PUE = Total Energy/Computer Energy\n        - 运维\n- 虚拟化（抽象） 解决多租户、多应用使用的问题 \n  \n  > 计算机科学中的所有问题，都可以通过增加一个层次的间接(indirectiron)来解决，当然除了间接层次过多的问题 —— David Wheeler\n\n虚拟化的结果 —— 每个用户认为自己有一套自己的架构，而实际所有人共享相同的硬件资源。\n\n![](http://doc.xr1228.com//post-images/1579969064114.png)\n\n\n# 二、虚拟化技术\n### 为什么要虚拟化？\n传统的虚拟化的目的主要是为了分区与抽象\n- 分区 Partitioning\n    - 分享：打破一个大资源\n    - 服务器\n- 抽象 Abstraction\n    - 用一个指令集仿真另一个指令集（简而言之就是一种操作系统使用另外一种系统）\n  \n在云计算时代，虚拟化是为了资源池，安全，便于管理\n- 资源池\n    - 聚合：将多个资源结合起来\n    - 合一：利于存储\n    - 动态：快速分配（虚拟机）\n- 隔离：保护消费者隔离其他租客\n    - 例如虚拟专用网（VPN）\n- 便于管理\n    - 测试\n    - 机动性\n  \n### 数据中心虚拟化的三个重要内容\n- 计算虚拟化\n  - 主操作系统：运行在真实机器上\n  - 客户操作系统：运行在主操作系统之上\n  - Hypervisor：支持运行在多个虚拟机上的软件\n    - 类型1:运行在真实机器上，例如 Xen、VMWARE、ESXi\n    - 类型2:运行在主操作系统，例如 MS Virtual PC\n    - 类型0:1和2兼有，例如 Linux KVM\n- 存储虚拟化\n- 网络虚拟化\n\n### 服务器虚拟化考虑的三个问题\n- 指令集的翻译 二进制翻译\n    - 如何快速执行\n    - 如何执行需要更高权限的指令\n- I/O设备的仿真\n    - 如何让虚拟机操作系统访问不支持的硬件\n    - 如何保护I/O性能\n- 保护处理器的数据结构 **影子**处理器\n\n### 虚拟化的核心问题：内存的保护管理\n![](http://doc.xr1228.com//post-images/1580566550776.png)\n计算机的内存映射是由MMU进行管理，当计算机虚拟化后运行在计算机上的多个系统对于MMU的控制方式是内存保护管理的重要问题。目前的解决方式：\n- 半虚拟化：修改虚拟机操作系统，能不做操作就不要作\n- 影子页表：\n    - 拒绝客户操作系统对实际页表条目的任何访问\n    - 捕获访问请求，在软件中仿真\n- 硬件支持的虚拟化：\n    - 二级地址转表（SLAT）\n        - AMD AMD-V RVI\n        - Intel VT-x EPT\n  \n> MMU是Memory Management Unit的缩写，中文名是内存管理单元，有时称作分页内存管理单元（英语：paged memory management unit，缩写为PMMU）。它是一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制。\n\n### 网络虚拟化\n#### 网络虚拟化的用途\n![](http://doc.xr1228.com//post-images/1580567311758.png)\n#### 网络虚拟化的举例 ： VLAN\n最简单的目标：提供单一的二层网络\n- 端口分数不同的VLAN\n- 多个VLAN共享一个端口\n    - Trunk模式\n    - VLAN标签（12bits）：特殊的包头\n    - 最多支持4096 VLAN\n- VLAN的优劣与解决方案\n    - 优势：标准，支持广泛，硬件成本低\n    - 劣势：只能支持4096个VLAN\n    - 新的标准：VxLAN\n        - 通过三层隧道实现\n        - 广播 -> 组播\n        - Virtual Tunnel End Ppoints（VTEPs）负责打包和接包\n#### 现代网络虚拟化技术：软件定义网络\n- 传统网络\n    - 控制面与数据面集成在同一个设备中\n    - 不同网络设备之间通过协议决定如何转发\n- 软件定义网络\n    - 控制面集中管理，放在服务器中\n    - 举例：OpenFlow协议，每一层交换机通过Controller确定数据流向\n  ![](http://doc.xr1228.com//post-images/1580614390079.png)\n    - 举例：Portland —— 大规模的虚拟二层网络的实现\n        - 大型2层网络的挑战\n            - 地址解析（ARP）：广播\n            - 路由：广播\n            - 转发：交换机要记住大量状态\n            - 根源：MAC地址不连续\n        - Portland实现\n            - 与位置相关的虚拟地址\n            - 通过SDN的地址解析\n                - 网络截获所有ARP广播\n                - 把无序的MAC地址改成与物理位置相关的地址\n                - 转发数据包\n                - 发给服务器之前，改回原来的MAC地址\n  #### 存储虚拟化\n  - 存储的意义\n    - 独立于数据位置\n        - 扩展性强，容量大\n        - 易于管理（磁盘可集中存储）\n        - 提升磁盘使用率\n    - 独立与物理存储技术\n        - 易于升级\n        - 可用性的优化（多路径访问、冗余）\n        - 易于维护（在线的后台备份、恢复）\n- 存储虚拟化的三类接口\n    - 块接口\n        - 本例块存储\n        - 远程块存储接口\n    - 文件接口\n        - 文件系统\n        - 网络文件系统（NFS，CIFS，HDFS）\n        - VFS\n    - 对象存储接口\n        - 亚马逊S3（基于http协议的REST接口）\n        - OpenStack Swift\n- 存储虚拟化的实现方式\n    - SAN 存储区域网络\n        - Storage Area Network\n        - 存储服务器通过专用网络链接，例如光纤通道（FC）\n    - NAS 网络附接存储\n        - Network attached storage（NAS）\n        - 存储服务器通过通用网络来访问，例如以太网\n### 总结\n- 优势\n    - 统一、抽象的接口隐藏了复杂的物理硬件\n    - 灵活，可以软件定义\n    - 易于管理，更容易保证安全\n- 问题\n    - 虚拟化有一定的资源开销\n    - 通常没有实现性能的隔离\n    - 过多层的抽象：如何调试 ？\n- 发展趋势：软件定义数据中心？\n    - 网络功能虚拟化\n        - 防火墙、入侵检测系统虚拟化\n    - 资源的管理和调度\n    - 其他资源的虚拟化：空调？供电？建筑？\n    - 目标：性能+灵活性+管理\n\n\n\n# 三、典型的云计算系统\n### 一个虚拟机的生命周期\n![](http://doc.xr1228.com//post-images/1580630632121.png)\n\n1. 用户通过界面或命令行向API发送 ‘create instance’\n2. API节点记录虚拟机信息，发送调度请求给调度器\n3. 调度器找到可用的计算节点，向计算节点发送‘vm provision’请求\n4. 计算节点通过虚拟机hypervisor启动虚拟机\n5. Hypervisor去**镜像存储服务**获取虚拟机磁盘镜像\n6. 计算节点向网络节点发信息，请求给新创虚拟机分配网络资源\n7. 网络节点通过配置虚拟交换机配置网桥、VLAN等，实现虚拟网络，并在数据库中记录网络信息\n8. 计算节点向虚拟存储服务要求新建虚拟磁盘卷，并通过iSCS协议挂载\n9. 用户通过界面查询虚拟机创建的结果\n\n> 以上操作是异步\n\n### 什么是一个好的云计算系统\n- 让用户彻底忘记底层的硬件（通过好的虚拟化和抽象，让用户忘记复杂的硬件与运算逻辑）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "data": {
        "title": "【工业与大数据】大数据基础",
        "date": "2020-01-23 23:59:47",
        "tags": [
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/da-shu-ju-de-ji-chu-jia-gou-yun-ji-suan.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "\n大数据这个词已经火热了很多年，似乎处处都存在着大数据的噱头，让我们回归本质，探讨一下大数据是什么？\n本文介绍了大数据技术细节以及相关背景的的一些概念。本文并未对大数据的相关知识进行总结，所以本文仅作为参考，无需详细阅读。",
      "fileName": "da-shu-ju-de-ji-chu-jia-gou-yun-ji-suan"
    },
    {
      "content": "接下来，让我们一起来完成一项具有一定实际价值的工作吧!\n\n在数据可视化领域，我们经常会使用**词云**来对文字中词语频率进行统计。网络当中也有许多类似[Wordle](http://www.wordle.net/) 、[图悦](http://www.picdata.cn/picdata/)图云生成网站。不过佛家有一句禅语：\n> 莫向外求，但从心觅\n\n我们可以片面的将这句话用在编程当中——双手敲过的代码才属于自己。 接下来就让我们通过Python自己编写一个词云生成器吧！\n\n首先是效果图，我节选了BOE(目前国内最大的面板生产企业)现任董事长在2018年全球创新合作伙伴峰会中的演讲，让词云通过分析这篇演讲稿来看看这位企业家为合作伙伴勾勒出的物联网蓝图是怎样的：\n![](http://doc.xr1228.com//post-images/1579701301281.png)\n\n服务、技术、创新这些词语在演讲中被大量提及，通过这样一张图片，就能对这篇演讲的大概内容有一定的了解。那么Python是如何生成这样一副文字大小颜色方向各异的复杂图片呢？\n其实十分简单，仍旧是老规矩，NoBB，Show Code！\n\n```python\n# 词云图\nimport matplotlib.pyplot as plt\nimport jieba\nfrom wordcloud import WordCloud\nfrom os import path\n\nlocalpath = path.dirname(__file__)  # 获取当前工作路径\n# 获取文件，注意这里要看编码格式\ntext = open(localpath+r'/words.txt', 'r', encoding='UTF-8').read()\n# 剪切单词\ntext_cut = jieba.cut(text)\n# 单词拼接\nresult = ' '.join(text_cut)\n# 生成次云图\nwc = WordCloud(\n    # 字体路径\n    font_path=localpath + r'/simhei.ttf',\n    # 背景颜色\n    background_color='white',\n    # 图片宽度\n    width=500,\n    height=350,\n    # 字体的大小\n    max_font_size=70,\n    min_font_size=5,\n)\n# 生成词云图片\nwc.generate(result)\nplt.imshow(wc)\nplt.axis('off')\nplt.show()\n```\n\n你一定很惊讶短短20多行代码就实现了词云这样复杂的功能。这都归功于Python丰富的各类库\n请允许我再次唠叨一下库的定义。\n\n- 所谓库就是Python提供的实现一类功能的具有目录层次结构的程序集合。\n\n简而言之，库就是Python提供给我们的，帮我们实现功能的工具包，每个工具包都能实现一个或者一类功能。本次程序我们用到了四个库：\n\n- matplotlib：Matplotlib是一个Python 2D绘图库，它能够快速辅助数据分析人员生成图表、直方图、功率谱、条形图、误差图、散点图。pyplot是Matplotlib的一个命令风格函数的集合，使matplotlib的机制更像 MATLAB，matplotlib的pyplot子库提供了和matlab类似的绘图API，方便用户快速绘制2D图表。\n- jieba：jieba是一种中文分词组建，他通过一定计算逻辑可以将一句完整的中文句子拆解成一个个词语。\n- wordcloud是Python用于构建词云的工具包，其功能强大，支持自定义词云各项参数。\n- path：这是Python标准库（自带的、无需安装的）中提供的用于文件访问、处理的库\n\n通过调用这些库的API，我们就能够很容易的实现词云这样复杂的图片。\n你肯定已经早早将程序敲到电脑中编译运行了，但是却出现了这样的错误：\n\n```cmd\n发生异常: ModuleNotFoundError\nNo module named 'matplotlib'\n```\n\n为什么呢？因为我们的程序中使用到了matplotlib、jieba、wordcloud这些外部库，外部库需要我们下载安装到自己电脑上才可以运行。坏消息是我们要下载三个库才能保证程序正常跑起来，好消息安装三个库非常容易！\n\n之前我们提到了包管理器，python内置了包管理器，使用包管理安装外部库的命令格式如下：\n\n```cmd\npip3 install SomePackage  \n```\n\n注意这里是pip3（在python进入3.X时代包管理应当使用pip3这个命令）\n\n接下来让我们开始安装所需的三个外部包。打开命令行程序（windows系统 开始➡️运行➡️cmd，MacOS系统使用终端）\n\n```cmd\npip3 install matplotlib  #安装matplotlib\n\npip3 install jieba  #安装jieba\n\npip3 install wordcloud  #安装wordcloud\n```\n\n不出意外的情况下这些包就都安装好了，如果安装过程中有疑问，最好百度/Google/dogedoge一下，善用搜索引擎。\n万事俱备只欠东风，接下来我们逐行对程序进行分析。\n\n```python\nimport matplotlib.pyplot as plt\n```\n\n- 这句话翻译成汉语很简单:引用matplotlib库的pyplot功能包，并将其命名为'plt'\n- matplotlib.pyplot 也可以写为  from matplotlib import pyplot这样的形式，这种形式我们在后面也会遇到，只需知道他的意思就是从matplotlib库中调用pyplot功能即可\n- 为什么要将其 as plt呢？ 很明显，就是因为 matplotlib.pyplot 太长了，后面我们要多次用到这个命令，索性给他起个名字，方便后续书写。这个名字可以随便命名（尽量符合驼峰命名规则）\n\n```python\nimport jieba\nfrom wordcloud import WordCloud\nfrom os import path\n```\n\n很简单，就是引入其他几个所需的库。（这里三个包都没有使用别名，因为本身长度就不长）\n\n```python\nlocalpath = path.dirname(__file__)  # 获取当前工作路径\n```\n\npython是一种若类型语言，所以我们定义变量“localpath”的时候并没有像其他编程语言一样 使用 string 类型符\n这句代码的意思是：定义一个变量“localpath”，给这个变量赋值为 当前工作路径。\n如何获取当前工作路径呢？使用的方法就是path.dirname(__file__)，这是Python os库中自带的方法，是不是非常方便？\n\n```python\n# 获取文件，注意这里要看编码格式\ntext = open(localpath+r'/words.txt', 'r', encoding='UTF-8').read()\n```\n\n这句话定义了一个变量 text，将工作目录下的 words.txt中的文字赋值给它。\n这里用到了一个 python的open()函数，open() 函数用于打开一个文件，创建一个 file 对象，相关的方法才可以调用它进行读写。\nopen()函数代码格式如下：\n\n```python\nopen(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n```\n\n- file: 必需，文件路径（相对或者绝对路径）。\n- mode: 可选，文件打开模式：只读，写入，追加等。我们采用了r模式，即默认文件访问模式。\n- buffering: 可选，设置缓冲，-1为采用系统默认缓存大小，0表示不使用，1表示使用，大于1的数字表示缓存区大小\n- encoding: 一般使用utf8（可以正常读取中文）\n- errors: 报错级别\n- newline: 区分换行符\n- closefd: 传入的file参数类型\n\n这个时候你可能有些疑惑🤔，道理都懂，但是为什么open()这个函数在这里要这样写？因为该教程的前半部分主要面向初学者，我们也没有经历过系统性的基础学习，这里对 编程语言中方法（函数）的调用进行说明。\n\n比如本例中 open(localpath+r'/words.txt', 'r', encoding='UTF-8') 这个语句\n\n- open()表示方法名，告知计算机我调用的是什么方法（函数）\n- open中所有内容，我们称之为参数，不同参数用\",\"分开。也就是说在本例中，我们调用open()方法，这个方法使用了三个参数\n- 第一个参数告知计算机文件的路径，localpath+r'/words.txt'  即工作目录下的words.txt文件\n- 第二个参数告知计算机我们采用 r 的模式读取文件（只读）\n- 第三个参数告诉计算机我们用的编码模式\n- 给方法定义参数的这个动作我们称之为 **传参**\n\n希望这样的解释能让你对编程工作中最基础最重要的 方法和参数有基本的理解。\n\n```python\n# 剪切单词\ntext_cut = jieba.cut(text)\n```\n\n这一句，我们调用了jieba的cut方法，将刚刚获取的文件内容text传如cut方法，这样jieba就将我们的text自动分词，分为一个一个单词组成的词组。最后将词组赋值给新定义的变量 text_cut\n\n```python\n# 单词拼接\nresult = ' '.join(text_cut)\n```\n\n这里有调用了一个join方法，传入我们的数组text_cut。什么意思呢？就是将这分好的一个个词语组合起来，使用空格隔开，组合成一个字符串。\n到这里，我们对于文章的处理就结束了，我们将原来的文章分成一个个词语，每个词语用空格隔开。为什么要这样处理呢？没有别的原因，就是因为我们后续调用的 wordcloud库就是这样规定的，他只能识别这样形式的数据。\n\n```python\n# 生成次云图\nwc = WordCloud(\n    # 字体路径\n    font_path=localpath + r'/simhei.ttf',\n    # 背景颜色\n    background_color='white',\n    # 图片宽度\n    width=500,\n    height=350,\n    # 字体的大小\n    max_font_size=70,\n    min_font_size=5,\n)\n# 生成词云图片\nwc.generate(result)\n```\n\n这里看似复杂，其实更加简单，我们调用了wordcould的方法，并在方法中传入若干参数，通过这些参数定义我们生成词云的样式。\n这里尤其需要注意 font_path=localpath + r'/simhei.ttf' 这一句必不可少，因为wordcloud必须知道自己使用的字体文件是什么样的才能正确生成词云。所以我们在工作目录中放入了一个simhei.ttf字体文件，方便wordcloud调用。\n\n这样我们的一个词云生成器 wc就定义好了，后续再调用 generate()方法并将处理好的数据变量result扔进去即可。\n\n```python\nplt.imshow(wc)\nplt.axis('off') \nplt.show()\n```\n\n词云做好了，如何让它显示出来？\n\n- 调用plt（就是开头引用的2D图像生成包）中imshow()方法将wc图片进行显示，\n- 调用plt.axis('off')让它不要生成坐标轴\n- 调用plt.show()方法使其显示出来。\n\n这样我们点击运行后一张词云图就显示出来了，注意工作目录中用到的 word.txt文件，simhei.ttf放在[github](https://github.com/Wuriqilang/WordCloud)中，你可以自行下载。如果不会使用github下载也没关系，自己在网上任意下一个ttf的字体文件，自己随便写一个word.txt文本文档放到我们写的python程序目录中即可。\n\n虽然我说的琐碎，但是在实际编写过程中相信你还是遇到许多问题，失败多次，各种环节出现奇葩的我没有提到的问题。\n没关系，多查多想多问。遇到问题，请在下方留言区留言\n\n[更多词云资料](https://zhuanlan.zhihu.com/p/27626809)\n[本例源代码](https://github.com/Wuriqilang/WordCloud)",
      "data": {
        "title": "【编程只是工具】Python实用手册03 词云",
        "date": "2020-01-22 21:53:45",
        "tags": [
          "python"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/python-shi-yong-shou-ce-03-ci-yun.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "python-shi-yong-shou-ce-03-ci-yun"
    },
    {
      "content": "虽然说学习一门语言，通常都是从命令行开始的。因为命令行涉及到的知识点最少，也不需复杂的功能依赖，初学者在命令行程序中很容易掌握各种语言的特性。但是这种相对枯燥乏味的学习方式很容易让人产生挫败感，花费数个小时研究学习后展示在我们眼前的就是冷冰冰的几行数字。所以让我们从 UI 编程开始学习，结合实际例子来快速入门吧。\n\n请在 VS Code 中新建一个.py 文件，输入以下内容。注意从现在开始，程序的输入切勿复制粘贴，自己敲进去代码和复制粘贴感觉是不同的！\n\n```python\nimport tkinter #引入Tkinter功能模块\n\nroot = tkinter.Tk() #实例化一个视窗对象\n\nmyLabel = tkinter.Label(root, text=\"Welcome to python's World\")  #在视窗对象中实例化一个Label对象\nmyLabel.pack() #将对象放在窗口中\n\nroot.mainloop()  # 进入主窗口消息循环\n```\n\n点击运行（F5）后,出现就出现了第一个属于你的 Python 视窗\n\n![](http://doc.xr1228.com//post-images/1579701131042.png)\n\n让我们来详细讲解以下这段代码：\n\n```python\nimport tkinter #引入Tkinter功能模块\n```\n\n什么叫做引入？什么叫做 Tkinter？\n\n- 引入：顾名思义，就是引用其他人写好的功能集（库）。这个功能有可能是 Python 内置的，也有可能是我们从包管理器下载来的。通过引入，我们就能用一行代码调用前人辛苦写好的功能，快速实现我们自己的需求。\n- Python 与包：Python 与包的关系，就如同工程师与设备的关系。今天工程师需要实现制作一个手机，那么我们就调来（引入）一个专门制作手机的机器，我不管这个机器是怎么造出来的，只要机器能生产出我们想要的手机即可。\n- 包管理器：接着上面的类比，工程师今天不想造手机了，想直接造人民币。但我们并没有现成的人民币制造机，怎么呢？我们进口一台人民币制造机就可以了。包管理器就是我们去进口机器的地方。——包管理器中存放着数以万计的凝聚力无数人心血的功能包，我们想要调用包管理器中的包时，只需要在命令行中输入“pip install ....(包的名字)“即可。 本例并未使用包管理器，后续我们会接触到。\n- Tkinter：Tkinter 模块(Tk 接口)是 Python 的标准 Tk GUI 工具包的接口。啥意思？就是说这就是一个 Python 中已经内置的专门用来画用户界面的包。\n\n所以说，这行代码乍看起来不明白，说白了就是调用一个用来画用户界面的包。\n\n```python\nroot = tkinter.Tk() #实例化一个视窗对象\n```\n\n如果你接触过其他编程语言，就会发现这条语句似曾相识却又有所不同。我们先来解释这几个刚看到的名词。\n\n- 对象：简而言之就是具有某些功能和特性的抽象化集合。面向对象的编程思想中，世间万物都可以抽象为对象。所谓“晓看天色暮看云，行也对象，坐也对象“。上述代码中的root，就是我们所需要的视窗对象，而tkinter.TK()，则是生成对象的方法。\n- 对象的实例化：其实举一个例子就很好懂。张无忌对对敌光明顶，想要使出一招乾坤大挪移，然而乾坤大挪移并不是一个实实在在的物体，怎么做呢？**他按照《九阳神功》的口诀，调用体内真气流转将乾坤大挪移激发出来。**这个过程就是**实例化**。\n\n![](http://doc.xr1228.com//post-images/1579701158947.gif)\n\n所以说, tkinter.TK() 就是九阳神功中运转乾坤大挪移的法门，root 则是我们实例化出得乾坤大挪移对象。只有将对象实例化后，我们才能操作他完来成一系列任务。\n\n希望前面的解释能让你能对编程世界中最常用的几个概念有所体会，事实上编程就如同搭积木一样，我们调用不同的积木，采用不同的组合最后实现自己的目的。在工业实践应用中，参与编程的工程师并不需要早早了解多么深刻的编程原理和数据结构，我们能够熟练使用这些积木，搭建出想要的城堡就够了。\n\n此时，视窗对象已经完成了实例化，我们希望这个视窗能够显示一个句子。所以我们要继续实例化出一个标签对象来承接我们的句子。所以我们用到了这样一条语句。\n\n```python\nmyLabel = tkinter.Label(root, text=\"Welcome to python's World\")  #在视窗对象中实例化一个Label对象\nmyLabel.pack() #将对象放在窗口中\n```\n\ntkinter.Label()就是生成Label对象的方法。而括号中的内容，则是**方法的传参**\n\n- 方法的传参：不要觉得这么多生词很难理解，其实简而言之，就是我们调用方法的时候，给定一些基本参数，让方法按照我们的设定执行。譬如我们调用了一个 \"做饭.鱼香肉丝()\"的方法，如果我们想要设定 肉300g,盐20g，在编程语言里就可以写成 “做饭.鱼香肉丝(肉=300，盐=20)“这样的形式。是不是很好理解呢？\n- 解释这条语句：为了实例化出一个标签对象，我们采用tkinter.Label()的方法，在这个方法中我们传入两个参数，\n  - 第一个参数：root。这是告诉这个方法，我们的Label是在root中生成的。\n  - 第二个参数：test。这是告诉这个方法，我们的Label要显示test中的内容。\n- myLable.pack():对象实例化出后还有一个重要步骤，就是让他显示出来，让Label显示出来的的方法是myLabel.pack().\n  \n**到这里你一定非常迷惑——为啥要这么写？我怎么可能记住这么多方法？**\n- 为啥要这么写？ ——这是tkinter的作者规定的，你按照他的规定写就好了，以后当你自己写方法的时候你也可以很方便的规定他。\n- 我怎么可能记住这么多方法？ —— “唯手熟尔”，当然装B的说法就是，这些常用的方法很好记的，不信你写几次就知道了。即使记不住也没关系，google以下即可。\n\n\n```python\nroot.mainloop()  # 进入主窗口消息循环\n```\n\n最后一句也很好理解，就是让我们的视窗对象在运行起来。\n\n希望这篇文章能对你有帮助，如果有任何疑问可以在下方评论区提出。",
      "data": {
        "title": "【编程只是工具】Python实用教程02  Python UI编程",
        "date": "2020-01-22 21:51:17",
        "tags": [
          "python"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/python-shi-yong-jiao-cheng-02-python-ui-bian-cheng.jpeg",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "python-shi-yong-jiao-cheng-02-python-ui-bian-cheng"
    },
    {
      "content": "让我们做一个小游戏吧,体会一下 Python 独特的魅力。\n<!-- more -->\n\n\n请在 VS Code 中新建一个.py 文件，或者是在命令行管理器中输入 Python（MacOS 输入 Python3）写入以下内容。\n\n```python\nprint('\\n'.join([''.join([('Chinese！'[(x-y)%8]if((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3<=0 else' ')for x in range(-30,30)])for y in range(15,-15,-1)]))\n```\n\n点击运行（F5）后,出现了一个中国心。是不是很有趣？将代码中 Chinese！ 修改为喜欢的姑娘的名字送给她吧！(注意必须是 8 个字符)\n\n![](http://doc.xr1228.com//post-images/1579701034908.png)\n\nPython 的魅力远不止于此,这段代码初学者还不需要明白是什么意思，让我们赶快进入到后面的学习吧！",
      "data": {
        "title": "【编程只是一种工具】Python实用教程01  一句话表白 ",
        "date": "2020-01-22 21:49:28",
        "tags": [
          "python"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/python-jiao-cheng-01.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "让我们做一个小游戏吧,体会一下 Python 独特的魅力。",
      "fileName": "python-jiao-cheng-01"
    },
    {
      "content": "\n> 人生苦短，我用 Python。 ——鲁迅\n\n## 写在开头\n\n本文档专注于编程语言在工业领域的实际应用，以实例讲解为主，还原编程语言的工具属性。这里会主要告诉你一个“工具怎么用”、“为什么要用”，但是不会过多涉及到“工具如何制造”以及“怎么用才更好”的问题。\n\n## Why Python\n\n- **天生优雅：** Python 使用了极为优雅精炼的语法与程序结构，一个简单的程序 C与JAVA 可能需要200行，而Python仅仅需要20行。Python提供了大量语法糖（或许你曾在比较各种语言优劣时听过这个词）Python就是将许多复杂的代码实现转化为精炼优雅符合人类直觉的书写方式，实用Python写程序时就如同孩子在吃糖果。\n- **开箱即用：** Python 提供了极为完善的基础代码库，很多看似复杂的程序实现可能仅仅需要调用Python中的一两个方法。对于一些复杂的图形处理，数据分析仅仅需要引入一两个依赖就能调用前人写好的功能模块。\n- **无所不能：** 受益于Python目前的热度，这个已经走过30年岁月的语言焕发出了无穷的活力。Python能够胜任从数据库，网络编程，机器学习各方面的应用。\n\n## Python 安装\n\nPython安装请选择最新版本3.7，网上有许多安装教程，这里不再赘述。[Python安装](https://www.liaoxuefeng.com/wiki/1016959663602400/1016959856222624)\n\n## 选用的编辑器\n\n按照编者的使用习惯，这里推荐使用VS Code作为您的Python编辑器。VS Code有以下优点：\n\n- 开源，免费；\n- 自定义配置\n- 集成git\n- 智能提示强大\n- 支持各种文件格式（html/jade/css/less/sass/xml）\n- 调试功能强大\n- 各种方便的快捷键\n- 强大的插件扩展\n简而言之，掌握了VS Code，你不但可以如丝般顺滑的编写Python程序，你具有了编写前端网页，Nodejs，文档……的能力。这样一把由微软打造的神兵谁会不喜欢呢？ [vs Code官网](https://code.visualstudio.com/)\n\n## VS Code安装汉化插件\n\nVS code安装汉化插件非常简单，打开vs Code后，选择左侧菜单栏中的插件商店，输入Chinese后选择Chinese (Simplified) Language Pack for Visual Studio Code点击 Install 即可。\n\nVS Code有很多优秀的插件能够极大的拓展VS Code功能，但如果你是编程初学者，建议先不要安装，让我们将更多注意力放在Python本身，以后按照自己的需要逐步拓展VS Code功能。\n\n## 一些学习Python的资源\n\n- Python基础学习 [廖雪峰Python教程](https://www.liaoxuefeng.com/wiki/1016959663602400)\n- 实用Python脚本学习视频 [实用主义教你学Python脚本](https://www.bilibili.com/video/av45221676)\n- [Tkinter 做简单的窗口视窗](https://www.bilibili.com/video/av16942112)\n",
      "data": {
        "title": "【编程只是一种工具】Python实用教程   介绍",
        "date": "2020-01-22 21:45:15",
        "tags": [
          "python"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/python.jpg",
        "isTop": true
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "python"
    },
    {
      "content": "\n## 一、为什么智能制造\n2016年7月，京东方的业务定位由一家半导体显示技术、产品和服务提供商转型为一家为信息交互和人类健康提供智慧端口产品和专业服务的物联网公司。在践行智能制造的过程中，我们开发了一套应用于京东方面板生产产线的设备智能监控系统。旨在消除设备监控死角，节约不良调查时间，减少工厂生产运营人力成本。将设备监控从“发现不良→调查设备→解决问题”的被动模式转化为”设备监控→预防不良”的主动模式。通过充分挖掘企业数据潜能，建立一套可视化、智能化的设备监控系统，将工程师从繁复的日常监控工作中解放出来,为公司运营提供长久动力。\n### 1.1 Array智造整体架构\n如何真正实现智能制造，将智能化生产应用于实际工厂运营当中来不同工厂有不同的思路。通过对我国智能制造试点示范项目进行分析，梳理出如下九种典型的智能制造新模式：\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567583134061-9095d2cc-1ced-4460-a1d0-b20f5a119eaa.png#align=left&display=inline&height=386&name=%E5%9B%BE%E7%89%87.png&originHeight=386&originWidth=587&size=118189&status=done&width=587)\n\n\n工厂的智能化程度取决于其对数据的利用程度。结合对京东方自动化程度以及实际生产制造模式，设计了一种以挖掘企业数据潜能为核心的智能制造模式。\n设备智能监控系统是一套建立在BOE工厂现有CIM系统基础上，以挖掘数据潜能为核心思路而设计的数据采集、处理、分析系统。这个系统由以下几个节点组成：\n1.设备端：高度信息化的设备实时信息发送给MES系统，通过EIS对信息格式进行统一。\n2.CIM端：通过MES、YMS、DFS、eMpa、SPC、BO等系统将生产信息，测试信息进行汇总处理，并提供端口供设备智能监控程序调用原始数据。\n3.监控端：智能监控程序将原始数据进行分析处理最后生成可视化程度、集成度高的信息反馈给工程师，并展示在Monitor看板，以便管理者掌握生产运营状态。\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567583254106-8d646a0c-d511-4e26-8363-63e59382842a.png#align=left&display=inline&height=320&name=%E5%9B%BE%E7%89%87.png&originHeight=320&originWidth=548&size=74161&status=done&width=548)\n\n\n所以说Array智造软件专注于应用层的开发，通过整合现有数据资源，通过软件来优化工程师工作效率，减少无用的重复的劳动。\n\n### 1.2 Array智造的基础 —— 数据\n本节重点介绍Array智造中的数据如如何获取的，并介绍了两个采集数据的软件。\n为了便于理解，下面将通过不同功能的的数据源获取方式来依次介绍Array智造的数据模块。\n#### 1.2.1 AOI Monitor的数据获取\nAOI Monitor在设计之初是单纯为日常Monitor工作服务的，所以采用了单一数据源 —— DFS\n\n- DFS 是公司提供的分布式文件存储服务，对于我们业务部门来说，其使用体验等同于共享。\n- 目前DFS 的统一访问地址是  10.120.8.52  账号是 dfssrv2\\cifsa  密码是 cifsa \n- 注意：AOI Monitor为访问Inform等常用功能开放了快捷方式，后续担当可以根据业务需求修改\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567584769308-57815052-ea59-4897-8f98-fb85eaaac450.png#align=left&display=inline&height=192&name=%E5%9B%BE%E7%89%87.png&originHeight=192&originWidth=226&size=7897&status=done&width=226)    ![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567584583410-1027da76-f284-42dd-93d9-7359c56a053f.png#align=left&display=inline&height=178&name=%E5%9B%BE%E7%89%87.png&originHeight=178&originWidth=404&size=39133&status=done&width=404)\n#### 1.2.2 CD Monitor的数据获取\nCD Monitor的数据流是 CD设备→曝光机共享→Monitor软件  来进行的，其获取数据的手段都是通过FileGee软件，该软件会在后面重点介绍。 该部分由马晓宇负责，如由疑问联系马晓宇。\n#### 1.2.3 IM Monitor的数据获取\nIM Monitor的数据来源如下：\n\n- DFS   包含了用户查询的IM Monitor图片信息\n- FTP   IM监控电脑不能访问共享，所以提交Abnormal时会先将Abnormal数据传到\n> FTP://10.120.9.22/【7】IM Abnormal\n\n- 共享  所有的Abnormal图片都会在存储在新共享\n> \\\\10.120.21.123\\Photo共享\\42.Photo工程部工作优化小组\\Array智造\\MuraHistor\n\n\n所以IM Monitor的数据流向如下\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567586067028-e975c41e-9c89-48cc-9b56-597a0626b153.png#align=left&display=inline&height=349&name=%E5%9B%BE%E7%89%87.png&originHeight=349&originWidth=1096&size=11649&status=done&width=1096)\n#### 1.2.4 THK Monitor\nTHK Monitor数据来源全部为共享，数据流如下\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567586183451-5e1e7fb1-b0a9-4bbe-98a5-7f7866258f86.png#align=left&display=inline&height=121&name=%E5%9B%BE%E7%89%87.png&originHeight=121&originWidth=1053&size=6779&status=done&width=1053)\n值得注意的是THK共享近期没有进行维护，后续担当需要开启。\n#### 1.2.5 设备监控\n设备监控中所有的数据都是从设备ProcessData中获取的，当我们将ProcessData保存到共享中，Array智造软件就可以方便的对数据进行处理和展示。其数据流向如下：\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567586828504-61a29a83-9785-4c56-9734-d43c4a0895ce.png#align=left&display=inline&height=667&name=%E5%9B%BE%E7%89%87.png&originHeight=667&originWidth=1110&size=29880&status=done&width=1110)\n\n值得注意的是：每天设备的数据现在设备上使用FTP Ghost软件简单处理后再利用FileGee进行上传\n\n#### 1.2.6 不良监控\n不良监控为了将各台设备的AOI Trend和工艺相关联起来，采取了比较复杂的数据获取方式。\n其数据获取方式与设备监控数据获取类似，重点在于将设备的工艺数据与DFS的测试数据相结合起来。\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567589162513-c0c2b6b2-ecb0-45c2-a1e7-ee86bfdb0c17.png#align=left&display=inline&height=659&name=%E5%9B%BE%E7%89%87.png&originHeight=659&originWidth=1106&size=30516&status=done&width=1106)\n#### 1.2.7 产能监控\n产能监控数据获取与设备监控相同，请参考 6.2.5\n\n\n#### 1.2.8 数据处理软件 参考附件【14】\n不难发现，上述各种数据获取离不开两个软件 FileGee与FTP Ghost。 具体使用方法较为复杂，已经单独交接给相关担当，软件请参考附件【14】\n\n### 1.3  智能制造的具体实现\n本节将介绍各软件模块的功能与基本实现思路，便于后续担当对软件进行进一步开发与维护。\n\n#### 1.3.1 AOI Monitor\nAOI Monitor目的是简化工程师日常Monitor流程，方便数据信息获取与基本的不良调查，其功能必须配合DFS使用，即用户电脑要开启DFS权限。AOI Monitor主要功能与实现如下：\n**AOI Monitor部分**\n\n\n- 通过LotID查询所有测试过得工序\n- 点击相应工序后显示测试过得Glass并且计算Total，对于异常Total使用红色显示\n- 点击跳转到DFS后能快捷跳转到DFS中，便于工程师看图\n\n**Tracing工具部分**\n\n- 通过GlassID查询所有测试过的工序\n- 多工序匹配Tracing结果，已经抓图的显示匹配结果，有Defect未抓图显示粉色背景，没有抓图显示灰色\n\n这里着重说一下Tracing工具的实现方式：先通过Data文件夹将所有Defect点位获取，匹配后（匹配规则是如果两个工序的点 X+Y的差＜0.5um且Y的差<0.5认为这两个点能够匹配到）筛选出查询到的Defect点并到Image文件夹中根据坐标找相应的图片，将图片地址存储到数据列表中，最后通过一定规则显示出来。\n\n\n#### ![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567588150931-63e193b6-bbd9-4e61-bc70-942ca4601f84.png#align=left&display=inline&height=220&name=%E5%9B%BE%E7%89%87.png&originHeight=823&originWidth=1130&size=415771&status=done&width=302)        ![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567588691160-49d5e579-b6bc-4cac-ac67-0d3662c67fa4.png#align=left&display=inline&height=223&name=%E5%9B%BE%E7%89%87.png&originHeight=823&originWidth=1138&size=231877&status=done&width=308)\n**Mapping工具**\n\n- 该功能尚未开发完成，目标是能够根据DefectCode对多张Glass，或者多个Lot或者一段时间内的defect进行Mapping，请后续担当继续开发，如有问题可以联系我。\n#### 1.3.2 IM Monitor\nIM Monitor主要功能与实现如下：\n\n- 通过LotID查询所有测试过得工序，并显示IM图片\n- IM图片查看时具有放大镜功能\n- 点击图片时自动计算点位与在LC机台上的位置\n- 点击发送Abnormal单跳转到Abnormal单界面，在Abnormal单可以输入不良点位，并对图片进行标注\n- 提交Abnormal单时自动计算，防止出现错误提交重复提交的情况\n- 提交后的Abnormal单自动保存到FTP并且同步到共享中，工程师打开软件可以看到之前开的Abnormal记录\n- 工程师可以对Abnormal单进行回复，回复后再记录界面显示回复情况，回复人等信息\n- 附加Mura管理手册，便于Monitor人员判断不良原因\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567589798924-4c6d99bc-c741-411a-bbef-00940806f74e.png#align=left&display=inline&height=923&name=%E5%9B%BE%E7%89%87.png&originHeight=923&originWidth=1239&size=116133&status=done&width=1239)\n#### 1.3.3  THK Monitor\n注：THK Monitor目的是统一管理膜厚数据，简化膜厚数据处理。\nTHK Monitor实现功能主要如下：\n\n- 从共享中中获取各设备测试历史，计算测试结果。 →**后续担当应该严格要求到班组将数据放入相应文件夹中**\n\n- 拖拽计算测试结果（支持用户把文件直接拖拽到软件中，自动计算）\n- 支持同时查看两次测试结果（3D/Cross可以放到一个界面）\n\n因为测试数据复杂，计算逻辑和可视化逻辑需要的步骤较多，目前THK Monitor不足之处：\n\n- 文件命名必须严格遵循命名规则 （详见5.1）\n\n- 对于3D的显示没有合适的Chart控件，所以没有显示三维图形。 →需要后续开发\n- \n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567648084311-11142500-65b7-4d1a-b92c-ae0f6e3de52d.png#align=left&display=inline&height=785&name=%E5%9B%BE%E7%89%87.png&originHeight=785&originWidth=1162&size=102181&status=done&width=1162)\n\n#### 1.3.4 设备管理系统\n设备管理系统承担着我们科室自动点检，设备状态监控，产能监控的重要使命。该部分需要详细介绍并后续担当重点优化与开发。\n##### 1.3.4.1 设备管理系统的两个软件版本\n为了优化设备的管理，在之前设备管理系统的基础上，开发了两个版本，他们在Array智造主界面的以下位置。\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567648651670-a55ae6b8-0281-4584-9d12-209cb0201242.png#align=left&display=inline&height=222&name=%E5%9B%BE%E7%89%87.png&originHeight=222&originWidth=1110&size=20182&status=done&width=1110)\n\n\n- 设备监控为旧版软件，包括了设备监控的绝大多数功能。\n- 设备管理为新版软件，包括了HoldList与自动点检、ProcssData查看等新功能\n\n**计划将旧版软件所有功能迁移到新版软件，但是时间有限，请后续担当继续推进。**\n##### 1.3.4.2 自动点检功能\n自动点检实现是将ProcessData中最新三张Glass数据与Spce表对比，如果其中有连续两张Glass都OutOfSPC，则提示设备参数异常。\n所以后续担当主要维护以下几点\n\n- 根据实际生产情况调整Spec\n- 根据实际生产情况设置报警逻辑\n- 根据工程师经验为每个参数设定调整建议和影响    \n\n同时自动点检功能为一些重点参数设定了快捷查看入口，对于TactTime也设立了可视化图表\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567649535066-521bef35-9c16-4555-8513-944b96f6c7fe.png#align=left&display=inline&height=825&name=%E5%9B%BE%E7%89%87.png&originHeight=825&originWidth=1354&size=175515&status=done&width=1354)\n\n##### 1.3.4.3 Tank监控\n为了避免Tank切换导致的批次性工艺不良，在主界面也可以显示目前PLN设备使用的Tank情况\n计算逻辑是：根据设备最近一张Glass使用Tank情况判断目前设备使用哪个Tank\n##### 1.3.4.4 VCD时间点检\n计算逻辑：根据设备最近几张Glass VCD工艺时间计算两个VCD Chamber的工艺时间差\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567649710578-67fa62aa-c044-4c18-8f1d-8f4920ac0a21.png#align=left&display=inline&height=493&name=%E5%9B%BE%E7%89%87.png&originHeight=493&originWidth=347&size=27243&status=done&width=347)\n\n\n##### 1.3.4.5 CD波动调查\n计算逻辑：根据设备ProcessData将某个Lot CD波动相关数据直观展示\n##### 1.3.4.6 Hold List\nHoldList实现逻辑相对较为复杂，具体实现方式\nBO自动发送邮件 → 通过OutLook功能自动下载附件至D盘→利用FileGee同步文件到共享→设备监控软件读取HoldList文件并筛选与Track相关Lot\n该功能重点在于邮箱附件的自动保存，但是这种方式费时费力还不好维护（OutLook的自动化功能也不稳定，后续我去CIM以后再进行修改吧）\n##### 1.3.4.7 自动化点检表\n为应对体系审核，需要对点检表进行自动生成，该功能放在设备管理系统中，具体交由王志敏维护，详见1.3.5\n##### 1.3.4.8 ProcessHistroy\n为便于查看ProcessData History，模仿产线内History功能。\n该功能未开发完成，有以下遗留问题：\n\n- 数据获取耗时较长，计算逻辑有待优化\n- 未加入可视化图表和数据筛选功能，需要进一步开发\n- \n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567650482748-27b87d01-0913-4f86-936f-92192ab25a6d.png#align=left&display=inline&height=981&name=%E5%9B%BE%E7%89%87.png&originHeight=981&originWidth=1303&size=65177&status=done&width=1303)\n\n#### 1.3.5 自动化点检表\n为应对体系检查，需要生成点检表。针对该问题开发功能如下：\n\n- 输入点检人，点击点检按钮对当日所有设备进行点检\n- 对于NG项目备注中提示NG原因，并提示已经调整OK\n- 点击保存点检结果后将点检数据保存到共享中\n- 点击SPEC设置，可以查看设定的Spec值，（暂未加入修改Spec功能，修改需要在共享中修改Txt文件）\n- 隐藏功能：选择StartTime→点击管理员功能  就可以实现从选择日期开始所有日期点检表的检查和保存\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567671153504-9972651b-53d9-427a-9855-720d91be2e91.png#align=left&display=inline&height=971&name=%E5%9B%BE%E7%89%87.png&originHeight=971&originWidth=1292&size=81412&status=done&width=1292)\n\n#### 1.3.6 不良监控系统\n为了优化不良调查流程，减少重复工作，开发了不良监控系统。\n目前实现功能如下：\n\n- 根据设备，日期，自动分析进行过的Lot，生成相关的Layer。\n- 根据用户选择的Layer，输入的Defect Code，生成Trend（时间按照Track进行Mask时间），Chamber别，Mapping结果。 （如果DefectCode输入所有不良，则刷取所有Code）\n- 支持切换DIPI和FIPI结果\n\n该功能仍有许多优化空间：\n\n- 目前尚未加入型号别刷取\n- 刷取速度很大一部分取决于电脑速度，可以通过更加优化的异步等方法优化。\n- 每次刷取是对时间和DFS资源的巨大负担，后续可以通过自动记录数据库的方式优化。（数据库已经进行过开发，但是受限于CS架构模式，暂时弃用）\n\n我们最终的目的是，10W左右的数据量能够在10s内显示出来，这必须依托于CS架构，所以我先去CIM学习了，后续开发可以联系我。\n\n#### 1.3.7 产能监控\n产能监控主要功能如下：\n\n- 根据用户选择设备，日期读取ProcessData，自动计算TactTime\n- 根据过滤条件选择计算相应TactTime\n- 计算cycleTime（但是cycleTime中部分EXP单元时间不正确，后续可以酌情调整）\n\n\n![图片.png](https://cdn.nlark.com/yuque/0/2019/png/332465/1567673699483-867c9f77-37a9-4c97-9d64-92738be78158.png#align=left&display=inline&height=771&name=%E5%9B%BE%E7%89%87.png&originHeight=771&originWidth=1240&size=101617&status=done&width=1240)\n\n#### 1.3.8 其他辅助功能\n智能制造中也开发了多项辅助功能，类似人工判图，Recipe自动生成等，请知悉。\n#### 1.3.9 Recipe自动备份 参考附件【14】\nRecipe自动备份是确保重要数据不丢失的手段。其实现方法是通过FileGee进行的，附件中提供了FileGee使用手册。\n目前建立自动备份的方法已经交接给张雪，姜欢欢。请知悉\n\n### 1.4 智能制造的开发 参考附件【15】\n#### 1.4.1 Array智造软件的发布与安装\n Array智造是一种CS构架的软件。CS架构是一种较为早期的软件架构模式，大多数的数据处理逻辑与运算是在客户端进行的，这种模式在效率和用户体验上有一定提升，但是每次用户安装和升级需要大量的工作。这里着重介绍一下Array智造软件的发布与安装。\n\n- 发布采用Visual Stuido自带的OneClick模式（类似于OIC的发布），这样的好处在于安装包存放在服务器或者共享中，提供给用户可以是一个2k的小安装程序。\n- 发布时开发者设置好 版本号，运行环境，安装地址后点击发布即可（具体有疑问联系我）\n- Array智造采用了 Task.Run（多线程）等.net FrameWork4.5 以上才有的功能，所以Win7电脑安装Array智造时需要先安装 .net FrameWork 4.5即以上  参考附件【16】\n\n#### 1.4.2 Array智造 开发环境构建\n\n- Array智造开发工具为 VS（Visual Studio 2017即以上），该软件有微软提供的社区免费版本，百度一下即可\n- Array智造选用的主要开发语言为C#，少量功能采用了 前端语言实现（html js css），后续担当简单学习即可，以解决实际工作需求为目的。\n- 经过大量对比测试，Array选用的技术框架为 Winform，这是一种比较古老的技术框架，但是适配性好，上手容易。\n- UI控件集选用了MetroFramework UI，并且根据其源码进行了一定程度的定制开发。推荐后续担当采用此框架\n\n#### 1.4.3 Array智造源代码\n\n- 因为Array智造本质也属于一种比较宝贵的脑力活动资产，源代码保留在我之前使用的科室笔记本电脑中，已经交际给担当 姜欢欢。\n#### 1.4.4 智能制造开发所需的一些学习资源  参考附件【17】\n\n- 编程学习推荐在网易云课堂搜索C#进行学习\n- 附件中提供了少量学习资料，多数学习教程存放在 科室笔记本电脑  D盘 学习资料中\n- 在Bilibili上也有很多C#语言相关的学习资源\n\n",
      "data": {
        "title": " 【智能制造之路】智能制造简述",
        "date": "2020-01-22 15:56:31",
        "tags": [
          "智能制造",
          "大数据"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/zhi-neng-zhi-zao-jian-shu.jpg",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "zhi-neng-zhi-zao-jian-shu"
    }
  ],
  "tags": [
    {
      "index": -1,
      "name": "值得一读",
      "slug": "worth",
      "used": true
    },
    {
      "index": -1,
      "name": "前端拾遗",
      "slug": "FE",
      "used": true
    },
    {
      "index": -1,
      "name": "SQL",
      "slug": "SQL",
      "used": true
    },
    {
      "index": 3,
      "name": "代码仓库",
      "slug": "code",
      "used": true
    },
    {
      "index": -1,
      "name": "智能制造",
      "slug": "smartManufacture",
      "used": true
    },
    {
      "index": -1,
      "name": "python",
      "slug": "python",
      "used": true
    },
    {
      "index": -1,
      "name": "大数据",
      "slug": "bigData",
      "used": true
    }
  ],
  "menus": [
    {
      "link": "/",
      "name": "首页",
      "openType": "Internal"
    },
    {
      "link": "/tags",
      "name": "分类",
      "openType": "Internal"
    },
    {
      "index": 3,
      "link": "/tag/python/",
      "name": "Python",
      "openType": "Internal"
    },
    {
      "link": "/tag/bigData/",
      "name": "工业与大数据",
      "openType": "Internal"
    },
    {
      "link": "/archives",
      "name": "归档",
      "openType": "Internal"
    },
    {
      "link": "/tag/code",
      "name": "代码库",
      "openType": "Internal"
    }
  ]
}